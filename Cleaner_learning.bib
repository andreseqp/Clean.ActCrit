
@misc{_Conceptual_,
  title = {Conceptual {{Learning}} in {{Bees}} | {{Proceedings}} of the {{Royal Society}} of {{London B}}: {{Biological Sciences}}},
  howpublished = {http://rspb.royalsocietypublishing.org/content/280/1772/20131907}
}

@misc{_How_,
  title = {How {{Adaptive Learning Affects Evolution}}: {{Reviewing Theory}} on the {{Baldwin Effect}} | {{SpringerLink}}},
  howpublished = {https://link.springer.com/article/10.1007/s11692-011-9155-2}
}

@misc{_Properties_,
  title = {Properties of {{Evolutionarily Stable Learning Rules}} - {{ScienceDirect}}},
  file = {D\:\\Zotero\\ZoteroLibrary\\zotero\\storage\\tracy1995.pdf},
  howpublished = {http://www.sciencedirect.com/science/article/pii/S002251938570238X}
}

@misc{_Using_,
  title = {Using an Integrative Approach to Investigate the Evolution of Behaviour - {{Aubin}}-{{Horth}} - 2015 - {{Evolutionary Applications}} - {{Wiley Online Library}}},
  howpublished = {http://onlinelibrary.wiley.com/doi/10.1111/eva.12300/abstract}
}

@article{adami_Use_2012,
  title = {The Use of Information Theory in Evolutionary Biology},
  author = {Adami, Christoph},
  year = {2012},
  month = may,
  volume = {1256},
  pages = {49--65},
  issn = {1749-6632},
  doi = {10.1111/j.1749-6632.2011.06422.x},
  file = {C\:\\Users\\andre\\Zotero\\storage\\AW9A7VAC\\Adami - 2012 - The use of information theory in evolutionary biol.pdf;C\:\\Users\\andre\\Zotero\\storage\\SGRI4HVU\\j.1749-6632.2011.06422.html},
  journal = {Annals of the New York Academy of Sciences},
  language = {en},
  number = {1}
}

@article{alonso_Special_2012,
  title = {Special Issue on Computational Models of Classical Conditioning Guest Editors' Introduction},
  author = {Alonso, Eduardo and Schmajuk, Nestor},
  year = {2012},
  month = sep,
  volume = {40},
  pages = {231--240},
  issn = {1543-4494, 1543-4508},
  doi = {10.3758/s13420-012-0081-7},
  abstract = {In the present special issue, the performance of current computational models of classical conditioning was evaluated under three requirements: (1) Models were to be tested against a list of previously agreed-upon phenomena; (2) the parameters were fixed across simulations; and (3) the simulations used to test the models had to be made available. These requirements resulted in three major products: (a) a list of fundamental classical-conditioning results for which there is a consensus about their reliability; (b) the necessary information to evaluate each of the models on the basis of its ordinal successes in accounting for the experimental data; and (c) a repository of computational models ready to generate simulations. We believe that the contents of this issue represent the 2012 state of the art in computational modeling of classical conditioning and provide a way to find promising avenues for future model development.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\6GBCRFHX\\Alonso and Schmajuk - 2012 - Special issue on computational models of classical.pdf;C\:\\Users\\andre\\Zotero\\storage\\AQCBNCFZ\\s13420-012-0081-7.html},
  journal = {Learn Behav},
  language = {en},
  number = {3}
}

@inproceedings{bacchus_Structured_1997,
  title = {Structured {{Solution Methods}} for Non-{{Markovian Decision Processes}}},
  booktitle = {Proceedings of the {{Fourteenth National Conference}} on {{Artificial Intelligence}} and {{Ninth Conference}} on {{Innovative Applications}} of {{Artificial Intelligence}}},
  author = {Bacchus, Fahiem and Boutilier, Craig and Grove, Adam},
  year = {1997},
  pages = {112--117},
  publisher = {{AAAI Press}},
  address = {{Providence, Rhode Island}},
  isbn = {0-262-51095-2},
  series = {{{AAAI}}'97/{{IAAI}}'97}
}

@book{barnes_Oceanography_2003,
  title = {Oceanography and {{Marine Biology}}: {{An Annual Review}}: {{Volume}} 38: {{An Annual Review}}:},
  shorttitle = {Oceanography and {{Marine Biology}}},
  author = {Barnes, Margaret and Gibson, R. N. and Gibson, R. N.},
  year = {2003},
  month = sep,
  publisher = {{Taylor \& Francis}},
  abstract = {A new edition of this thorough, comprehensive and respected review source for oceanographers and marine biologists. A must for every station, institute and university involved with marine biology.},
  googlebooks = {BZV5AgAAQBAJ},
  isbn = {978-1-134-55654-0},
  keywords = {Science / Earth Sciences / Oceanography,Science / Life Sciences / Marine Biology,Technology \& Engineering / Fisheries \& Aquaculture},
  language = {en}
}

@article{barto_Recent_2003,
  title = {Recent {{Advances}} in {{Hierarchical Reinforcement Learning}}},
  author = {Barto, Andrew G. and Mahadevan, Sridhar},
  year = {2003},
  month = oct,
  volume = {13},
  pages = {341--379},
  issn = {0924-6703, 1573-7594},
  doi = {10.1023/A:1025696116075},
  abstract = {Reinforcement learning is bedeviled by the curse of dimensionality: the number of parameters to be learned grows exponentially with the size of any compact encoding of a state. Recent attempts to combat the curse of dimensionality have turned to principled ways of exploiting temporal abstraction, where decisions are not required at each step, but rather invoke the execution of temporally-extended activities which follow their own policies until termination. This leads naturally to hierarchical control architectures and associated learning algorithms. We review several approaches to temporal abstraction and hierarchical organization that machine learning researchers have recently developed. Common to these approaches is a reliance on the theory of semi-Markov decision processes, which we emphasize in our review. We then discuss extensions of these ideas to concurrent activities, multiagent coordination, and hierarchical memory for addressing partial observability. Concluding remarks address open challenges facing the further development of reinforcement learning in a hierarchical setting.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\IZMKVS98\\Barto and Mahadevan - 2003 - Recent Advances in Hierarchical Reinforcement Lear.pdf;C\:\\Users\\andre\\Zotero\\storage\\KT5665NT\\A1025696116075.html},
  journal = {Discrete Event Dynamic Systems},
  language = {en},
  number = {4}
}

@book{begon_Ecology_2006,
  title = {Ecology: {{From Individuals}} to {{Ecosystems}}},
  shorttitle = {Ecology},
  author = {Begon, Michael and Townsend, Colin R. and Harper, John L.},
  year = {2006},
  month = jan,
  edition = {4 edition},
  publisher = {{Wiley-Blackwell}},
  address = {{Malden, MA}},
  abstract = {Begon, Townsend, and Harper's Ecology has long been regarded as the definitive textbook on all aspects of ecology. This new edition provides a comprehensive treatment of the subject, from the first principles of ecology to the current state of the field, and aims to improve students' preparedness to address the environmental problems of the new millennium. Thoroughly revised and updated, this fourth edition includes:  three new chapters on applied ecology, reflecting a rigorous, scientific approach to the ecological problems now facing mankind discussion of over 800 new studies, updating the text throughout an updated, user-friendly design with margin notes and chapter summaries that serve as study aids  The resulting textbook is easy to use, lucid and up-to-date, and is the essential reference for all students whose degree program includes ecology and for practicing ecologists.},
  isbn = {978-1-4051-1117-1},
  language = {English}
}

@book{black_Classical_1972,
  title = {Classical Conditioning {{II}}: Current Research and Theory},
  shorttitle = {Classical Conditioning {{II}}},
  author = {Black, Abraham H. and Prokasy, William Frederick},
  year = {1972},
  publisher = {{Appleton-Century-Crofts}},
  googlebooks = {T4oQAQAAIAAJ},
  language = {en}
}

@article{bogacz_Theory_2017,
  title = {Theory of Reinforcement Learning and Motivation in the Basal Ganglia},
  author = {Bogacz, Rafal},
  year = {2017},
  month = aug,
  pages = {174524},
  doi = {10.1101/174524},
  abstract = {This paper proposes how the neural circuits in vertebrates select actions on the basis of past experience and the current motivational state. According to the presented theory, the basal ganglia evaluate the utility of considered actions by combining the positive consequences (e.g. nutrition) scaled by the motivational state (e.g. hunger) with the negative consequences (e.g. effort). The theory suggests how the basal ganglia compute utility by combining the positive and negative consequences encoded in the synaptic weights of striatal Go and No-Go neurons, and the motivational state carried by neuromodulators including dopamine. Furthermore, the theory suggests how the striatal neurons to learn separately about consequences of actions, and how the dopaminergic neurons themselves learn what level of activity they need to produce to optimize behaviour. The theory accounts for the effects of dopaminergic modulation on behaviour, patterns of synaptic plasticity in striatum, and responses of dopaminergic neurons in diverse situations.},
  copyright = {\textcopyright{} 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  file = {C\:\\Users\\andre\\Zotero\\storage\\H86A7EU4\\Bogacz - 2017 - Theory of reinforcement learning and motivation in.pdf;C\:\\Users\\andre\\Zotero\\storage\\C83CX9VZ\\174524.html},
  journal = {bioRxiv},
  language = {en}
}

@article{botvinick_Hierarchically_2009,
  title = {Hierarchically Organized Behavior and Its Neural Foundations: {{A}} Reinforcement Learning Perspective},
  shorttitle = {Hierarchically Organized Behavior and Its Neural Foundations},
  author = {Botvinick, Matthew M. and Niv, Yael and Barto, Andrew C.},
  year = {2009},
  month = dec,
  volume = {113},
  pages = {262--280},
  issn = {00100277},
  doi = {10.1016/j.cognition.2008.08.011},
  file = {C\:\\Users\\andre\\Zotero\\storage\\BWPMTNTD\\Botvinick-Niv-Barto-hierarchical-reinforcement-learning-Cog09.pdf},
  journal = {Cognition},
  language = {en},
  number = {3}
}

@article{bshary_Choosy_2002,
  title = {Choosy Reef Fish Select Cleaner Fish That Provide High-Quality Service},
  author = {Bshary, Redouan and Sch{\"a}ffer, Daniel},
  year = {2002},
  month = mar,
  volume = {63},
  pages = {557--564},
  issn = {0003-3472},
  doi = {10.1006/anbe.2001.1923},
  abstract = {Reef fish that actively visit cleaner fish to have parasites and dead or infected tissue removed face two potential problems: they might have to wait while cleaners inspect other clients, and cleaners might feed on healthy body tissue, a behaviour that is referred to as cheating. Individuals of some `client' species have large home ranges, which cover several cleaning stations, while others have small territories or home ranges with access to only one cleaning station. The former can thus choose between cleaners, while the latter cannot. We investigated whether clients with large home ranges change cleaning partners to outplay cleaners against each other to achieve (1) priority of access over clients with no choice at cleaning stations and (2) control over cheating by cleaners. We followed individuals of longnosed parrotfish, Hipposcarus harid, for up to 120min in their natural environment and noted their interactions with cleaner wrasses, Labroides dimidiatus. Individuals were likely to return to the same cleaning station if the previous interaction had ended without conflict but changed cleaners for the next inspection if they had been either cheated or ignored, at least if the time between two consecutive visits was short. The overall attractiveness of a cleaning station seemed to be largely independent of service quality, which appeared to be similar at all stations. This is the first empirical evidence that the option to change partners is used as a control mechanism to stabilize cooperative behaviour.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\H4IWFGFQ\\S0003347201919232.html},
  journal = {Animal Behaviour},
  number = {3}
}

@article{bshary_Punishment_2005,
  title = {Punishment and Partner Switching Cause Cooperative Behaviour in a Cleaning Mutualism},
  author = {Bshary, Redouan and Grutter, Alexandra S},
  year = {2005},
  month = dec,
  volume = {1},
  pages = {396--399},
  issn = {1744-9561},
  doi = {10.1098/rsbl.2005.0344},
  abstract = {What are the mechanisms that prevent partners from cheating in potentially cooperative interactions between unrelated individuals? The cleaner fish Labroides dimidiatus and client reef fish both benefit from an interaction as long as the cleaner eats ectoparasites. However, the cleaner fish prefers some client mucus, which constitutes cheating. Field observations suggested that clients control such cheating by using punishment (chasing the cleaner) or by switching partners (fleeing from the cleaner). Here, we tested experimentally whether such client behaviours result in cooperative cleaner fish. Cleaners were allowed to feed from Plexiglas plates containing prawn items and fish flake items. A lever attached to the plates allowed us to mimic the behaviours of clients. As cleaners showed a strong preference for prawn over flakes, we taught them that eating their preferred food would cause the plate to either chase them or to flee, while feeding on flakes had no negative consequences. We found a significant shift in cleaner fish foraging behaviour towards flake feeding after six learning trials. As punishment and terminating an interaction resulted in the cleaners feeding against their preferences in our experiment, we propose that the same behaviours in clients improve the service quality of cleaners under natural conditions.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\CBBJQ9CU\\Bshary and Grutter - 2005 - Punishment and partner switching cause cooperative.pdf},
  journal = {Biol Lett},
  number = {4},
  pmcid = {PMC1626376},
  pmid = {17148216}
}

@article{bshary_Social_2014,
  title = {Social Cognition in Fishes},
  author = {Bshary, Redouan and Gingins, Simon and Vail, Alexander L.},
  year = {2014},
  month = sep,
  volume = {18},
  pages = {465--471},
  issn = {1364-6613, 1879-307X},
  doi = {10.1016/j.tics.2014.04.005},
  file = {C\:\\Users\\andre\\Zotero\\storage\\D4WC6CKG\\Bshary et al. - 2014 - Social cognition in fishes.pdf;C\:\\Users\\andre\\Zotero\\storage\\Q7QJ5KDS\\S1364-6613(14)00099-0.html},
  journal = {Trends in Cognitive Sciences},
  keywords = {behavior,ecological approach,fish,physiology,social cognition},
  language = {English},
  number = {9},
  pmid = {24815200}
}

@article{bush_Mathematical_1951,
  title = {A Mathematical Model for Simple Learning},
  author = {Bush, Robert R. and Mosteller, Frederick},
  year = {1951},
  volume = {58},
  pages = {313--323},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/h0054388},
  abstract = {A mathematical model to describe simple learning situations, with special attention to the acquisition and extinction of behavior habits in the straight runway and the Skinner box. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {C\:\\Users\\a.quinones\\Zotero\\storage\\LZ4TJMPN\\bush1951.pdf;C\:\\Users\\andre\\Zotero\\storage\\LZ4TJMPN\\1952-03262-001.html},
  journal = {Psychological Review},
  keywords = {Habits,learning,Mathematical Modeling,Skinner Boxes},
  number = {5}
}

@article{chittka_What_2012,
  title = {What Is Comparable in Comparative Cognition?},
  author = {Chittka, Lars and Rossiter, Stephen J. and Skorupski, Peter and Fernando, Chrisantha},
  year = {2012},
  month = oct,
  volume = {367},
  pages = {2677--2685},
  doi = {10.1098/rstb.2012.0215},
  abstract = {To understand how complex, or `advanced' various forms of cognition are, and to compare them between species for evolutionary studies, we need to understand the diversity of neural\textendash computational mechanisms that may be involved, and to identify the genetic changes that are necessary to mediate changes in cognitive functions. The same overt cognitive capacity might be mediated by entirely different neural circuitries in different species, with a many-to-one mapping between behavioural routines, computations and their neural implementations. Comparative behavioural research needs to be complemented with a bottom-up approach in which neurobiological and molecular-genetic analyses allow pinpointing of underlying neural and genetic bases that constrain cognitive variation. Often, only very minor differences in circuitry might be needed to generate major shifts in cognitive functions and the possibility that cognitive traits arise by convergence or parallel evolution needs to be taken seriously. Hereditary variation in cognitive traits between individuals of a species might be extensive, and selection experiments on cognitive traits might be a useful avenue to explore how rapidly changes in cognitive abilities occur in the face of pertinent selection pressures.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\QUL4CJAR\\Chittka Lars et al. - 2012 - What is comparable in comparative cognition.pdf;C\:\\Users\\andre\\Zotero\\storage\\KZV4BFWS\\rstb.2012.html},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  number = {1603}
}

@article{conway_Sequential_2001,
  title = {Sequential Learning in Non-Human Primates},
  author = {Conway, Christopher M. and Christiansen, Morten H.},
  year = {2001},
  volume = {5},
  pages = {539--546},
  file = {C\:\\Users\\andre\\Zotero\\storage\\AUNN34F8\\conway2001.pdf},
  journal = {Trends in cognitive sciences},
  number = {12}
}

@article{cote_Evolution_2000,
  title = {Evolution and Ecology of Cleaning Symbioses in the Sea},
  author = {C{\^o}t{\'e}, I M},
  year = {2000},
  volume = {38},
  pages = {311--355},
  abstract = {A new edition of this thorough, comprehensive and respected review source for oceanographers and marine biologists. A must for every station, institute and university involved with marine biology.},
  googlebooks = {BZV5AgAAQBAJ},
  journal = {Oceanography and Marine Biology Annual Review},
  keywords = {Science / Earth Sciences / Oceanography,Science / Life Sciences / Marine Biology,Technology \& Engineering / Fisheries \& Aquaculture},
  language = {en}
}

@article{croston_Heritability_2015,
  title = {Heritability and the Evolution of Cognitive Traits},
  author = {Croston, R. and Branch, C. L. and Kozlovsky, D. Y. and Dukas, R. and Pravosudov, V. V.},
  year = {2015},
  month = nov,
  volume = {26},
  pages = {1447--1459},
  issn = {1045-2249},
  doi = {10.1093/beheco/arv088},
  abstract = {A critical question in the study of the evolution of cognition and the brain concerns the extent to which variation in cognitive processes and associated neural mechanisms is adaptive and shaped by natural selection. In order to be available to selection, cognitive traits and their neural architecture must show heritable variation within a population, yet heritability of cognitive and neural traits is not often investigated in the field of behavioral ecology. In this commentary, we outline existing research pertaining to the relative influences of genes and environment in cognitive and underlying neural trait variation, as well as what is known of their heritable genetic architecture by focusing on several cognitive traits that have received much attention in behavioral ecology. It is important to demonstrate that cognitive traits can respond to selection, and we advocate for an increased emphasis on investigating trait heritability for enhancing our understanding of the ecological, genetic and neurobiological mechanisms that have shaped interspecific and intraspecific variation in cognitive traits.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\4WEUBQ4E\\Croston et al. - 2015 - Heritability and the evolution of cognitive traits.pdf;C\:\\Users\\andre\\Zotero\\storage\\357QFKMJ\\Heritability-and-the-evolution-of-cognitive-traits.html},
  journal = {Behav Ecol},
  number = {6}
}

@article{dallal_Hierarchical_1990,
  title = {Hierarchical Structures: Chunking by Food Type Facilitates Spatial Memory.},
  shorttitle = {Hierarchical Structures},
  author = {Dallal, Nancy L. and Meck, Warren H.},
  year = {1990},
  volume = {16},
  pages = {69},
  file = {C\:\\Users\\andre\\Zotero\\storage\\GYJPT4EL\\dallal1990.pdf},
  journal = {Journal of Experimental Psychology: Animal Behavior Processes},
  number = {1}
}

@article{dayan_Reinforcement_2008,
  title = {Reinforcement Learning: {{The Good}}, {{The Bad}} and {{The Ugly}}},
  shorttitle = {Reinforcement Learning},
  author = {Dayan, Peter and Niv, Yael},
  year = {2008},
  month = apr,
  volume = {18},
  pages = {185--196},
  issn = {09594388},
  doi = {10.1016/j.conb.2008.08.003},
  file = {C\:\\Users\\andre\\Zotero\\storage\\YS4PXRMY\\Dayan and Niv - 2008 - Reinforcement learning The Good, The Bad and The .pdf},
  journal = {Current Opinion in Neurobiology},
  language = {en},
  number = {2}
}

@article{dridi_Environmental_2016,
  title = {Environmental Complexity Favors the Evolution of Learning},
  author = {Dridi, Slimane and Lehmann, Laurent},
  year = {2016},
  month = jan,
  volume = {27},
  pages = {842--850},
  issn = {1045-2249},
  doi = {10.1093/beheco/arv184},
  abstract = {Learning is a fundamental biological adaptation that is widespread throughout the animal kingdom. According to previous research, 2 conditions are necessary for learning to be adaptive: between-generation environmental variability and within-generation environmental predictability. In this article, we show that between-generation variability is not necessary and that instrumental learning can provide a selective advantage in a complex environment, where an individual is exposed to a large number of different challenges during its lifespan. We construct an evolutionary model where individuals have a memory with limited storage capacity, and an evolving trait determines the fraction of that memory that should be allocated to innate responses to the environment versus learning these responses. The evolutionarily stable level of learning depends critically on the features of the environmental process, but generally increases with environmental complexity. We conclude by emphasizing that the specific advantages of learning should be distinguished from the general advantages of phenotypic plasticity, and we discuss possible routes to empirically test our claims.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\ARVFURXD\\Dridi and Lehmann - 2016 - Environmental complexity favors the evolution of l.pdf;C\:\\Users\\andre\\Zotero\\storage\\ERNCIC7C\\Environmental-complexity-favors-the-evolution-of.html},
  journal = {Behav Ecol},
  number = {3}
}

@article{dridi_Learning_2017,
  title = {Learning to {{Cooperate}}: {{The Evolution}} of {{Social Rewards}} in {{Repeated Interactions}}},
  shorttitle = {Learning to {{Cooperate}}},
  author = {Dridi, Slimane and Ak{\c c}ay, Erol},
  year = {2017},
  month = nov,
  pages = {000--000},
  issn = {0003-0147},
  doi = {10.1086/694822},
  abstract = {Understanding the behavioral and psychological mechanisms underlying social behaviors is one of the major goals of social evolutionary theory. In particular, a persistent question about animal cooperation is to what extent it is supported by other-regarding preferences\textemdash the motivation to increase the welfare of others. In many situations, animals adjust their behaviors through learning by responding to the rewards they experience as a consequence of their actions. Therefore, we may ask whether learning in social situations can be driven by evolved other-regarding rewards. Here we develop a mathematical model in order to ask whether the mere act of cooperating with a social partner will evolve to be inherently rewarding. Individuals interact repeatedly in pairs and adjust their behaviors through reinforcement learning. We assume that individuals associate with each game outcome an internal reward value. These perceived rewards are genetically evolving traits. We find that conditionally cooperative rewards that value mutual cooperation positively but the sucker's outcome negatively tend to be evolutionarily stable. Purely other-regarding rewards can evolve only under special parameter combinations. On the other hand, selfish rewards that always lead to pure defection are also evolutionarily successful. These findings are consistent with empirical observations showing that humans tend to display conditionally cooperative behavior and also exhibit a diversity of preferences. Our model also demonstrates the need to further integrate multiple levels of biological causation of behavior.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\6AN35ZT8\\Dridi and Akçay - 2017 - Learning to Cooperate The Evolution of Social Rew.pdf;C\:\\Users\\andre\\Zotero\\storage\\HKU2262U\\694822.html},
  journal = {The American Naturalist}
}

@article{enquist_Power_2016,
  title = {The Power of Associative Learning and the Ontogeny of Optimal Behaviour},
  author = {Enquist, Magnus and Lind, Johan and Ghirlanda, Stefano},
  year = {2016},
  month = nov,
  volume = {3},
  pages = {160734},
  issn = {2054-5703},
  doi = {10.1098/rsos.160734},
  file = {C\:\\Users\\andre\\Zotero\\storage\\FZ77GJ4V\\Enquist_associative.pdf},
  journal = {Royal Society Open Science},
  language = {en},
  number = {11}
}

@article{esber_Reconciling_2011,
  title = {Reconciling the Influence of Predictiveness and Uncertainty on Stimulus Salience: A Model of Attention in Associative Learning},
  shorttitle = {Reconciling the Influence of Predictiveness and Uncertainty on Stimulus Salience},
  author = {Esber, Guillem R. and Haselgrove, Mark},
  year = {2011},
  month = sep,
  volume = {278},
  pages = {2553--2561},
  issn = {0962-8452, 1471-2954},
  doi = {10.1098/rspb.2011.0836},
  abstract = {Theories of selective attention in associative learning posit that the salience of a cue will be high if the cue is the best available predictor of reinforcement (high predictiveness). In contrast, a different class of attentional theory stipulates that the salience of a cue will be high if the cue is an inaccurate predictor of reinforcement (high uncertainty). Evidence in support of these seemingly contradictory propositions has led to: (i) the development of hybrid attentional models that assume the coexistence of separate, predictiveness-driven and uncertainty-driven mechanisms of changes in cue salience; and (ii) a surge of interest in identifying the neural circuits underpinning these mechanisms. Here, we put forward a formal attentional model of learning that reconciles the roles of predictiveness and uncertainty in salience modification. The issues discussed are relevant to psychologists, behavioural neuroscientists and neuroeconomists investigating the roles of predictiveness and uncertainty in behaviour.},
  copyright = {This journal is \textcopyright{} 2011 The Royal Society},
  file = {C\:\\Users\\andre\\Zotero\\storage\\W3AVIEQC\\Esber and Haselgrove - 2011 - Reconciling the influence of predictiveness and un.pdf;M\:\\storage\\W3AVIEQC\\rspb20110836supp1.doc;C\:\\Users\\andre\\Zotero\\storage\\GN56XN88\\2553.html},
  journal = {Proceedings of the Royal Society of London B: Biological Sciences},
  language = {en},
  number = {1718},
  pmid = {21653585}
}

@article{fawcett_Evolution_2014,
  title = {The Evolution of Decision Rules in Complex Environments},
  author = {Fawcett, Tim W. and Fallenstein, Benja and Higginson, Andrew D. and Houston, Alasdair I. and Mallpress, Dave E. W. and Trimmer, Pete C. and McNamara, John M.},
  year = {2014},
  month = mar,
  volume = {18},
  pages = {153--161},
  issn = {1364-6613, 1879-307X},
  doi = {10.1016/j.tics.2013.12.012},
  file = {C\:\\Users\\andre\\Zotero\\storage\\VTMRZSAH\\Fawcett et al. - 2014 - The evolution of decision rules in complex environ.pdf;C\:\\Users\\andre\\Zotero\\storage\\EDGCFG3S\\S1364-6613(13)00297-0.html},
  journal = {Trends in Cognitive Sciences},
  language = {English},
  number = {3},
  pmid = {24467913}
}

@article{fawcett_Exposing_2013,
  title = {Exposing the Behavioral Gambit: The Evolution of Learning and Decision Rules},
  shorttitle = {Exposing the Behavioral Gambit},
  author = {Fawcett, Tim W. and Hamblin, Steven and Giraldeau, Luc-Alain},
  year = {2013},
  month = jan,
  volume = {24},
  pages = {2--11},
  issn = {1045-2249, 1465-7279},
  doi = {10.1093/beheco/ars085},
  abstract = {Behavioral ecologists have long been comfortable assuming that genetic architecture does not constrain which phenotypescan evolve (the ``phenotypic gambit''). For flexible behavioral traits, however, solutions to adaptive problems are reached not only by genetic evolution but also by behavioral changes within an individual's lifetime, via psychological mechanisms such as learning. Standard optimality approaches ignore these mechanisms, implicitly assuming that they do not constrain the expression of adaptive behavior. This assumption, which we dub the behavioral gambit, is sometimes wrong: evolved psychological mechanisms can prevent animals from behaving optimally in specific situations. To understand the functional basis of behavior, we would do better by considering the underlying mechanisms, rather than the behavioral outcomes they produce, as the target of selection. This change of focus yields new, testable predictions about evolutionary equilibria, the development of behavior, and the properties of cognitive systems. Studies on the evolution of learning rules hint at the potential insights to be gained, but such mechanism-based approaches are underexploited. We highlight three future research priorities: (1) systematic theoretical analysis of the evolutionary properties of learning rules; (2) detailed empirical study of how animals learn in nonforaging contexts;and (3) analysis of individual differences in learning rules and their associated fitness consequences.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\SR9GDIWE\\Fawcett_gambit.pdf;C\:\\Users\\andre\\Zotero\\storage\\8ZHFQHH2\\2.html},
  journal = {Behavioral Ecology},
  keywords = {behavioral flexibility,behavioral plasticity,behaviorally stable strategy,game theory,learning rules,optimality},
  language = {en},
  number = {1}
}

@article{ferrari_Generalization_2007,
  title = {Generalization of Learned Predator Recognition: An Experimental Test and Framework for Future Studies},
  shorttitle = {Generalization of Learned Predator Recognition},
  author = {Ferrari, Maud C. O. and Gonzalo, Adega and Messier, Fran{\c c}ois and Chivers, Douglas P.},
  year = {2007},
  month = aug,
  volume = {274},
  pages = {1853--1859},
  issn = {0962-8452, 1471-2954},
  doi = {10.1098/rspb.2007.0297},
  abstract = {While some prey species possess an innate recognition of their predators, others require learning to recognize their predators. The specific characteristics of the predators that prey learn and whether prey can generalize this learning to similar predatory threats have been virtually ignored. Here, we investigated whether fathead minnows that learned to chemically recognize a specific predator species as a threat has the ability to generalize their recognition to closely related predators. We found that minnows trained to recognize the odour of a lake trout as a threat (the reference predator) generalized their responses to brook trout (same genus as lake trout) and rainbow trout (same family), but did not generalize to a distantly related predatory pike or non-predatory suckers. We also found that the intensity of antipredator responses to the other species was correlated with the phylogenetic distance to the reference predator; minnows responded with a higher intensity response to brook trout than rainbow trout. This is the first study showing that prey have the ability to exhibit generalization of predator odour recognition. We discuss these results and provide a theoretical framework for future studies of generalization of predator recognition.},
  copyright = {\textcopyright{} 2007 The Royal Society},
  file = {C\:\\Users\\andre\\Zotero\\storage\\SP5GSST3\\Ferrari et al. - 2007 - Generalization of learned predator recognition an.pdf;C\:\\Users\\andre\\Zotero\\storage\\SYI7PZXW\\1853.html},
  journal = {Proceedings of the Royal Society of London B: Biological Sciences},
  language = {en},
  number = {1620},
  pmid = {17519190}
}

@article{frankenhuis_Enriching_2018,
  title = {Enriching Behavioral Ecology with Reinforcement Learning Methods},
  author = {Frankenhuis, Willem E. and Panchanathan, Karthik and Barto, Andrew G.},
  year = {2018},
  month = feb,
  issn = {0376-6357},
  doi = {10.1016/j.beproc.2018.01.008},
  abstract = {This article focuses on the division of labor between evolution and development in solving sequential, state-dependent decision problems. Currently, behavioral ecologists tend to use dynamic programming methods to study such problems. These methods are successful at predicting animal behavior in a variety of contexts. However, they depend on a distinct set of assumptions. Here, we argue that behavioral ecology will benefit from drawing more than it currently does on a complementary collection of tools, called reinforcement learning methods. These methods allow for the study of behavior in highly complex environments, which conventional dynamic programming methods do not feasibly address. In addition, reinforcement learning methods are well-suited to studying how biological mechanisms solve developmental and learning problems. For instance, we can use them to study simple rules that perform well in complex environments. Or to investigate under what conditions natural selection favors fixed, non-plastic traits (which do not vary across individuals), cue-driven-switch plasticity (innate instructions for adaptive behavioral development based on experience), or developmental selection (the incremental acquisition of adaptive behavior based on experience). If natural selection favors developmental selection, which includes learning from environmental feedback, we can also make predictions about the design of reward systems. Our paper is written in an accessible manner and for a broad audience, though we believe some novel insights can be drawn from our discussion. We hope our paper will help advance the emerging bridge connecting the fields of behavioral ecology and reinforcement learning.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\UE6UEZ5C\\Frankenhuis et al. - 2018 - Enriching behavioral ecology with reinforcement le.pdf;C\:\\Users\\andre\\Zotero\\storage\\3GA585TN\\S0376635717303637.html},
  journal = {Behavioural Processes},
  keywords = {Adaptation,Development,Dynamic programming,Evolution,learning,Reinforcement learning}
}

@article{ghirlanda_Artificial_1998,
  title = {Artificial Neural Networks as Models of Stimulus Control},
  author = {GHIRLANDA, STEFANO and ENQUIST, MAGNUS},
  year = {1998},
  month = dec,
  volume = {56},
  pages = {1383--1389},
  issn = {0003-3472},
  doi = {10.1006/anbe.1998.0903},
  abstract = {We evaluate the ability of artificial neural network models (multilayer perceptrons) to predict stimulus\textendash response relationships. A variety of empirical results are considered, such as generalization, peak shift (supernormality) and stimulus intensity effects. The networks were trained on the same tasks as the animals in the experiments considered. The subsequent generalization tests on the networks showed that the model replicates correctly the empirical results. We conclude that these models are valuable tools in the study of animal behaviour.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\IVICAH46\\GhirlandaEnquist1998.pdf;C\:\\Users\\andre\\Zotero\\storage\\IQ36NCA8\\S0003347298909034.html},
  journal = {Animal Behaviour},
  number = {6}
}

@article{ghirlanda_Century_2003,
  title = {A Century of Generalization},
  author = {Ghirlanda, Stefano and Enquist, Magnus},
  year = {2003},
  month = jul,
  volume = {66},
  pages = {15--36},
  issn = {00033472},
  doi = {10.1006/anbe.2003.2174},
  file = {C\:\\Users\\andre\\Zotero\\storage\\MINXS8KW\\ghirlanda2003.pdf},
  journal = {Animal Behaviour},
  language = {en},
  number = {1}
}

@article{ghirlanda_Geometry_1999,
  title = {The Geometry of Stimulus Control},
  author = {GHIRLANDA, STEFANO and ENQUIST, MAGNUS},
  year = {1999},
  month = oct,
  volume = {58},
  pages = {695--706},
  issn = {0003-3472},
  doi = {10.1006/anbe.1999.1187},
  abstract = {Many studies, both in ethology and comparative psychology, have shown that animals react to modifications of familiar stimuli. This phenomenon is often referred to as generalization. The majority of modifications lead to a decrease in responding, but to certain new stimuli an increase in responding is observed. This holds for both innate and learned behaviour. Here we propose a heuristic approach to stimulus control, or stimulus selection, with the aim of explaining these phenomena. The model has two key elements. First, we choose the receptor level as the fundamental stimulus space. Each stimulus is represented as the pattern of activation it induces in sense organs. Second, in this space we introduce a simple measure of `similarity' between stimuli by calculating how activation patterns overlap. The main advantage in this approach is that the generalization of acquired responses emerges from a few simple principles that are grounded in the recognition of how animals actually perceive stimuli. Many traditional problems that face theories of stimulus control (e.g. the Spence\textendash Hull theory of gradient interaction or ethological theories of stimulus summation) do not arise in the present framework. These problems include the amount of generalization along different dimensions, peak shift phenomena (with respect to both positive and negative shifts), intensity generalization and generalization after conditioning on two positive stimuli.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\4SJ94DUT\\GhirlandaEnquist1999.pdf;C\:\\Users\\andre\\Zotero\\storage\\7W246QP4\\S0003347299911879.html},
  journal = {Animal Behaviour},
  number = {4}
}

@article{ghirlanda_How_2007,
  title = {How Training and Testing Histories Affect Generalization: A Test of Simple Neural Networks},
  shorttitle = {How Training and Testing Histories Affect Generalization},
  author = {Ghirlanda, S. and Enquist, M.},
  year = {2007},
  month = mar,
  volume = {362},
  pages = {449--454},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2006.1972},
  file = {C\:\\Users\\andre\\Zotero\\storage\\2IVPV7NU\\GhirlandaEnquist2007.pdf},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  language = {en},
  number = {1479}
}

@article{giske_Effects_2013,
  title = {Effects of the {{Emotion System}} on {{Adaptive Behavior}}.},
  author = {Giske, Jarl and Eliassen, Sigrunn and Fiksen, {\O}yvind and Jakobsen, Per J. and Aksnes, Dag L. and J{\o}rgensen, Christian and Mangel, Marc},
  year = {2013},
  month = dec,
  volume = {182},
  pages = {689--703},
  issn = {0003-0147},
  doi = {10.1086/673533},
  abstract = {A central simplifying assumption in evolutionary behavioral ecology has been that optimal behavior is unaffected by genetic or proximate constraints. Observations and experiments show otherwise, so that attention to decision architecture and mechanisms is needed. In psychology, the proximate constraints on decision making and the processes from perception to behavior are collectively described as the emotion system. We specify a model of the emotion system in fish that includes sensory input, neuronal computation, developmental modulation, and a global organismic state and restricts attention during decision making for behavioral outcomes. The model further includes food competition, safety in numbers, and a fluctuating environment. We find that emergent strategies in evolved populations include common emotional appraisal of sensory input related to fear and hunger and also include frequency-dependent rules for behavioral responses. Focused attention is at times more important than spatial behavior for growth and survival. Spatial segregation of the population is driven by personality differences. By coupling proximate and immediate influences on behavior with ultimate fitness consequences through the emotion system, this approach contributes to a unified perspective on the phenotype, by integrating effects of the environment, genetics, development, physiology, behavior, life history, and evolution.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\Q7BUTFUB\\Giske et al. - 2013 - Effects of the Emotion System on Adaptive Behavior.pdf;C\:\\Users\\andre\\Zotero\\storage\\MJBA6STM\\673533.html},
  journal = {The American Naturalist},
  number = {6}
}

@article{glimcher_Understanding_2011,
  title = {Understanding Dopamine and Reinforcement Learning: {{The}} Dopamine Reward Prediction Error Hypothesis},
  shorttitle = {Understanding Dopamine and Reinforcement Learning},
  author = {Glimcher, Paul W.},
  year = {2011},
  month = sep,
  volume = {108},
  pages = {15647--15654},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1014269108},
  abstract = {A number of recent advances have been achieved in the study of midbrain dopaminergic neurons. Understanding these advances and how they relate to one another requires a deep understanding of the computational models that serve as an explanatory framework and guide ongoing experimental inquiry. This intertwining of theory and experiment now suggests very clearly that the phasic activity of the midbrain dopamine neurons provides a global mechanism for synaptic modification. These synaptic modifications, in turn, provide the mechanistic underpinning for a specific class of reinforcement learning mechanisms that now seem to underlie much of human and animal behavior. This review describes both the critical empirical findings that are at the root of this conclusion and the fantastic theoretical advances from which this conclusion is drawn.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\NLZPFGX2\\Glimcher - 2011 - Understanding dopamine and reinforcement learning.pdf;C\:\\Users\\andre\\Zotero\\storage\\824GRWY2\\15647.html},
  journal = {PNAS},
  language = {en},
  number = {Supplement 3},
  pmid = {21389268}
}

@article{gobet_Chunking_2001,
  title = {Chunking Mechanisms in Human Learning},
  author = {Gobet, Fernand and Lane, Peter CR and Croker, Steve and Cheng, Peter CH and Jones, Gary and Oliver, Iain and Pine, Julian M.},
  year = {2001},
  volume = {5},
  pages = {236--243},
  file = {C\:\\Users\\andre\\Zotero\\storage\\P8SLZRWT\\gobet2001.pdf},
  journal = {Trends in cognitive sciences},
  number = {6}
}

@article{goldstein_General_2010,
  title = {General Cognitive Principles for Learning Structure in Time and Space},
  author = {Goldstein, Michael H. and Waterfall, Heidi R. and Lotem, Arnon and Halpern, Joseph Y. and Schwade, Jennifer A. and Onnis, Luca and Edelman, Shimon},
  year = {2010},
  month = jun,
  volume = {14},
  pages = {249--258},
  issn = {13646613},
  doi = {10.1016/j.tics.2010.02.004},
  file = {C\:\\Users\\andre\\Zotero\\storage\\7SENKD8R\\goldstein2010.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {6}
}

@article{griffiths_Probabilistic_2010,
  title = {Probabilistic Models of Cognition: Exploring Representations and Inductive Biases},
  shorttitle = {Probabilistic Models of Cognition},
  author = {Griffiths, Thomas L. and Chater, Nick and Kemp, Charles and Perfors, Amy and Tenenbaum, Joshua B.},
  year = {2010},
  month = aug,
  volume = {14},
  pages = {357--364},
  issn = {13646613},
  doi = {10.1016/j.tics.2010.05.004},
  file = {C\:\\Users\\andre\\Zotero\\storage\\Q95SN83K\\Griffiths et al 2010 TICS Probabilistic models of cognition.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {8}
}

@article{grutter_Cleaner_2003,
  title = {Cleaner Wrasse Prefer Client Mucus: Support for Partner Control Mechanisms in Cleaning Interactions},
  shorttitle = {Cleaner Wrasse Prefer Client Mucus},
  author = {Grutter, Alexandra S. and Bshary, Redouan},
  year = {2003},
  month = nov,
  volume = {270},
  pages = {S242-S244},
  issn = {0962-8452, 1471-2954},
  doi = {10.1098/rsbl.2003.0077},
  abstract = {Recent studies on cleaning behaviour suggest that there are conflicts between cleaners and their clients over what cleaners eat. The diet of cleaners usually contains ectoparasites and some client tissue. It is unclear, however, whether cleaners prefer client tissue over ectoparasites or whether they include client tissue in their diet only when searching for parasites alone is not profitable. To distinguish between these two hypotheses, we trained cleaner fish Labroides dimidiatus to feed from plates and offered them client mucus from the parrotfish Chlorurus sordidus, parasitic monogenean flatworms, parasitic gnathiid isopods and boiled flour glue as a control. We found that cleaners ate more mucus and monogeneans than gnathiids, with gnathiids eaten slightly more often than the control substance. Because gnathiids are the most abundant ectoparasites, our results suggest a potential for conflict between cleaners and clients over what the cleaner should eat, and support studies emphasizing the importance of partner control in keeping cleaning interactions mutualistic.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\ZYN5B4V5\\Grutter and Bshary - 2003 - Cleaner wrasse prefer client mucus support for pa.pdf;C\:\\Users\\andre\\Zotero\\storage\\GI9V7P9L\\S242.html},
  journal = {Proceedings of the Royal Society of London B: Biological Sciences},
  language = {en},
  number = {Suppl 2},
  pmid = {14667394}
}

@article{grutter_Spatial_1994,
  title = {Spatial and Temporal Variations of the Ectoparasites of Seven Reef Fish Species from {{Lizard Island}} and {{Heron Island}}, {{Australia}}},
  author = {Grutter, Alexandra S.},
  year = {1994},
  pages = {21--30},
  file = {C\:\\Users\\andre\\Zotero\\storage\\WH2UZW8I\\m115p021.pdf},
  journal = {Marine Ecology Progress Series}
}

@article{hamblin_Finding_2009,
  title = {Finding the Evolutionarily Stable Learning Rule for Frequency-Dependent Foraging},
  author = {Hamblin, Steven and Giraldeau, Luc-Alain},
  year = {2009},
  volume = {78},
  pages = {1343--1350},
  issn = {0003-3472},
  doi = {http://dx.doi.org/10.1016/j.anbehav.2009.09.001},
  file = {M\:\\storage\\hamblin2009.pdf},
  journal = {Animal Behaviour},
  keywords = {producer–scrounger game},
  number = {6}
}

@article{hammerstein_Biological_2016,
  title = {Biological Trade and Markets},
  author = {Hammerstein, Peter and No{\"e}, Ronald},
  year = {2016},
  month = feb,
  volume = {371},
  pages = {20150101},
  doi = {10.1098/rstb.2015.0101},
  abstract = {Cooperation between organisms can often be understood, like trade between merchants, as a mutually beneficial exchange of services, resources or other `commodities'. Mutual benefits alone, however, are not sufficient to explain the evolution of trade-based cooperation. First, organisms may reject a particular trade if another partner offers a better deal. Second, while human trade often entails binding contracts, non-human trade requires unwritten `terms of contract' that `self-stabilize' trade and prevent cheating even if all traders strive to maximize fitness. Whenever trading partners can be chosen, market-like situations arise in nature that biologists studying cooperation need to account for. The mere possibility of exerting partner choice stabilizes many forms of otherwise cheatable trade, induces competition, facilitates the evolution of specialization and often leads to intricate forms of cooperation. We discuss selected examples to illustrate these general points and review basic conceptual approaches that are important in the theory of biological trade and markets. Comparing these approaches with theory in economics, it turns out that conventional models\textemdash often called `Walrasian' markets\textemdash are of limited relevance to biology. In contrast, early approaches to trade and markets, as found in the works of Ricardo and Cournot, contain elements of thought that have inspired useful models in biology. For example, the concept of comparative advantage has biological applications in trade, signalling and ecological competition. We also see convergence between post-Walrasian economics and biological markets. For example, both economists and biologists are studying `principal\textendash agent' problems with principals offering jobs to agents without being sure that the agents will do a proper job. Finally, we show that mating markets have many peculiarities not shared with conventional economic markets. Ideas from economics are useful for biologists studying cooperation but need to be taken with caution.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\KVHM6FZU\\Hammerstein Peter and Noë Ronald - 2016 - Biological trade and markets.pdf;C\:\\Users\\andre\\Zotero\\storage\\P5RAKQ2N\\rstb.2015.html},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  number = {1687}
}

@article{harley_Learning_1981,
  title = {Learning the Evolutionarily Stable Strategy},
  author = {Harley, Calvin B.},
  year = {1981},
  month = apr,
  volume = {89},
  pages = {611--633},
  issn = {0022-5193},
  doi = {10.1016/0022-5193(81)90032-1},
  abstract = {The possibility that animals learn a ``developmentally stable strategy'' (DSS) (Dawkins, 1980) is an alternative in biological game theory to the idea that evolutionarily stable strategies (ESS) (Maynard Smith, 1972) are genetically determined. A learning rule is defined as a rule which assigns for every possible behaviour the probability of displaying that behaviour at each trial of a game as a function of previous payoffs. This report examines properties of the evolutionarily stable (ES) learning rule, i.e. the rule which, when adopted by a population, is uninvadable by a mutant with a different learning rule. The DSS is defined as the strategy used by individuals with the ES learning rule. With some simplifying assumptions, it is shown that the DSS is the ESS: the ES learning rule is a rule for learning ESSs. This and other properties of the ES learning rule suggested that an approximation to such a rule is the relative payoff sum (RPS) learning rule, which states that the probability of displaying a behaviour is equal to the cumulative payoff for that behaviour relative to the total sum of payoffs for the game. Residual payoffs and a memory factor are incorporated into the RPS learning rule to account for prior expectations of payoff and the decay of memory with time. Both features are adaptive. In simulations of several frequency dependent and frequency independent games using the RPS learning rule, the response of the simulated animals was consistent with the predictions of the ES learning rule. This analysis has shown how ESSs may be achieved by non-genetic means. The RPS learning rule is described in molecular terms utilizing synthesis, storage, and degradation of a substance which elicits the behavioural response. If the RPS learning rule is used by animals, it should be possible to identify within neurons substances whose synthesis is regulated by behavioural stimuli and which initiate alternative behaviours in proportion to their concentrations.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\LCKHTRRI\\0022519381900321.html},
  journal = {Journal of Theoretical Biology},
  number = {4}
}

@article{hasinoff_Reinforcement_2002,
  title = {Reinforcement Learning for Problems with Hidden State},
  author = {Hasinoff, Samuel W.},
  year = {2002},
  file = {C\:\\Users\\andre\\Zotero\\storage\\7NCXCBNE\\hasinoff-rlhidden-2002.pdf},
  journal = {University of Toronto, Technical Report}
}

@article{herre_Evolution_1999,
  title = {The Evolution of Mutualisms: Exploring the Paths between Conflict and Cooperation},
  shorttitle = {The Evolution of Mutualisms},
  author = {Herre, E. A. and Knowlton, N. and Mueller, U. G. and Rehner, S. A.},
  year = {1999},
  month = feb,
  volume = {14},
  pages = {49--53},
  issn = {0169-5347},
  doi = {10.1016/S0169-5347(98)01529-8},
  abstract = {Mutualisms are of fundamental importance in all ecosystems but their very existence poses a series of challenging evolutionary questions. Recently, the application of molecular analyses combined with theoretical advances have transformed our understanding of many specific systems, thereby contributing to the possibility of a more general understanding of the factors that influence mutualisms.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\QW94VXVD\\S0169534798015298.html},
  journal = {Trends in Ecology \& Evolution},
  keywords = {coevolution,conflict of interest,cooperation,molecular phylogeny,mutualism,scale,symbiosis},
  language = {en},
  number = {2}
}

@article{herrnstein_Law_1970,
  title = {On the Law of Effect},
  author = {Herrnstein, R. J.},
  year = {1970},
  month = mar,
  volume = {13},
  pages = {243--266},
  issn = {0022-5002},
  doi = {10.1901/jeab.1970.13-243},
  abstract = {Experiments on single, multiple, and concurrent schedules of reinforcement find various correlations between the rate of responding and the rate or magnitude of reinforcement. For concurrent schedules (i.e., simultaneous choice procedures), there is matching between the relative frequencies of responding and reinforcement; for multiple schedules (i.e., successive discrimination procedures), there are contrast effects between responding in each component and reinforcement in the others; and for single schedules, there are a host of increasing monotonic relations between the rate of responding and the rate of reinforcement. All these results, plus several others, can be accounted for by a coherent system of equations, the most general of which states that the absolute rate of any response is proportional to its associated relative reinforcement.},
  journal = {J Exp Anal Behav},
  number = {2},
  pmcid = {PMC1333768},
  pmid = {16811440}
}

@article{herrnstein_Law_1970a,
  title = {On the Law of Effect},
  author = {Herrnstein, R. J.},
  year = {1970},
  month = mar,
  volume = {13},
  pages = {243--266},
  issn = {0022-5002},
  doi = {10.1901/jeab.1970.13-243},
  abstract = {Experiments on single, multiple, and concurrent schedules of reinforcement find various correlations between the rate of responding and the rate or magnitude of reinforcement. For concurrent schedules (i.e., simultaneous choice procedures), there is matching between the relative frequencies of responding and reinforcement; for multiple schedules (i.e., successive discrimination procedures), there are contrast effects between responding in each component and reinforcement in the others; and for single schedules, there are a host of increasing monotonic relations between the rate of responding and the rate of reinforcement. All these results, plus several others, can be accounted for by a coherent system of equations, the most general of which states that the absolute rate of any response is proportional to its associated relative reinforcement.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\32YJHJSV\\Herrnstein - 1970 - On the law of effect.pdf},
  journal = {J Exp Anal Behav},
  number = {2},
  pmcid = {PMC1333768},
  pmid = {16811440}
}

@book{herrnstein_Matching_2000,
  title = {The {{Matching Law}}: {{Papers}} in {{Psychology}} and {{Economics}}},
  shorttitle = {The {{Matching Law}}},
  author = {Herrnstein, Richard J.},
  editor = {Rachlin, Howard and Laibson, David I.},
  year = {2000},
  month = may,
  publisher = {{Harvard University Press}},
  address = {{Cambridge, Mass.; London}},
  abstract = {This impressive collection features Richard Herrnstein's most important and original contributions to the social and behavioral sciences--his papers on choice behavior in animals and humans and on his discovery and elucidation of a general principle of choice called the matching law.In recent years, the most popular theory of choice behavior has been rational choice theory. Developed and elaborated by economists over the past hundred years, it claims that individuals make choices in such a way as to maximize their well-being or utility under whatever constraints they face; that is, people make the best of their situations. Rational choice theory holds undisputed sway in economics, and has become an important explanatory framework in political science, sociology, and psychology. Nevertheless, its empirical support is thin.The matching law is perhaps the most important competing explanatory account of choice behavior. It views choice not as a single event or an internal process of the organism but as a rate of observable events over time. It states that instead of maximizing utility, the organism allocates its behavior over various activities in exact proportion to the value derived from each activity. It differs subtly but significantly from rational choice theory in its predictions of how people exert self-control, for example, how they decide whether to forgo immediate pleasures for larger but delayed rewards. It provides, through the primrose path hypothesis, a powerful explanation of alcohol and narcotic addiction. It can also be used to explain biological phenomena, such as genetic selection and foraging behavior, as well as economic decision making.},
  isbn = {978-0-674-00177-0},
  language = {English}
}

@article{heyes_Homo_2016,
  title = {Homo Imitans? {{Seven}} Reasons Why Imitation Couldn9t Possibly Be Associative},
  shorttitle = {Homo Imitans?},
  author = {Heyes, Cecilia},
  year = {2016},
  month = jan,
  volume = {371},
  pages = {20150069},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2015.0069},
  abstract = {Many comparative and developmental psychologists believe that we are Homo imitans; humans are more skilled and prolific imitators than other animals, because we have a special, inborn `intermodal matching' mechanism that integrates representations of others with representations of the self. In contrast, the associative sequence learning (ASL) model suggests that human infants learn to imitate using mechanisms that they share with other animals, and the rich resources provided by their sociocultural environments. This article answers seven objections to the ASL model: (i) it presents evidence that newborns do not imitate; (ii) argues that infants receive a plentiful supply of the kind of experience necessary for learning to imitate; (iii) suggests that neither infants nor adults can imitate elementally novel actions; (iv) explains why non-human animals have a limited capacity for imitation; (v) discusses the goal-directedness of imitation; (vi) presents evidence that improvement in imitation depends on visual feedback; and (vii) reflects on the view that associative theories steal `the soul of imitation'. The empirical success of the ASL model indicates that the mechanisms which make imitation possible, by aligning representations of self with representations of others, have been tweaked by cultural evolution, not built from scratch by genetic evolution.},
  copyright = {\textcopyright{} 2015 The Author(s). http://royalsocietypublishing.org/licence},
  file = {C\:\\Users\\andre\\Zotero\\storage\\XURNHRWJ\\Heyes - 2016 - Homo imitans Seven reasons why imitation couldn9t.pdf;C\:\\Users\\andre\\Zotero\\storage\\N7MW3P6M\\20150069.html},
  journal = {Phil. Trans. R. Soc. B},
  language = {en},
  number = {1686},
  pmid = {26644604}
}

@article{hochman_Partialreinforcement_2013,
  title = {The Partial-Reinforcement Extinction Effect and the Contingent-Sampling Hypothesis},
  author = {Hochman, Guy and Erev, Ido},
  year = {2013},
  month = dec,
  volume = {20},
  pages = {1336--1342},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-013-0432-1},
  file = {C\:\\Users\\andre\\Zotero\\storage\\66XUIXBW\\Parital reinforcement and extinction Hochman and Erev 2013.pdf},
  journal = {Psychonomic Bulletin \& Review},
  language = {en},
  number = {6}
}

@article{hughes_Optimizing_1992,
  title = {Optimizing Foraging Behaviour through Learning},
  author = {Hughes, R. N. and Kaiser, M. J. and Mackney, P. A. and Warburton, K.},
  year = {1992},
  volume = {41},
  pages = {77--91},
  issn = {1095-8649},
  doi = {10.1111/j.1095-8649.1992.tb03870.x},
  abstract = {Manifestation of life-history strategy is through the allocation of resources acquired by foraging. Foraging efficiency can be improved by learning, as fishes adjust their behaviour to changing circumstances. We briefly review the influence of learning on the foraging behaviour of fishes and make recommendations for further research. We stress the importance of quantifying learning and memory in relation to ontogeny and life history.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\J7GXG7NJ\\j.1095-8649.1992.tb03870.html},
  journal = {Journal of Fish Biology},
  keywords = {Foraging behaviour,learning,memory},
  language = {en},
  number = {sB}
}

@article{hughes_Optimizing_1992a,
  title = {Optimizing Foraging Behaviour through Learning},
  author = {Hughes, R. N. and Kaiser, M. J. and Mackney, P. A. and Warburton, K.},
  year = {1992},
  volume = {41},
  pages = {77--91},
  issn = {1095-8649},
  doi = {10.1111/j.1095-8649.1992.tb03870.x},
  abstract = {Manifestation of life-history strategy is through the allocation of resources acquired by foraging. Foraging efficiency can be improved by learning, as fishes adjust their behaviour to changing circumstances. We briefly review the influence of learning on the foraging behaviour of fishes and make recommendations for further research. We stress the importance of quantifying learning and memory in relation to ontogeny and life history.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\B6WWPEN9\\j.1095-8649.1992.tb03870.html},
  journal = {Journal of Fish Biology},
  keywords = {Foraging behaviour,learning,memory},
  language = {en},
  number = {sB}
}

@article{kacelnik_Rate_1985,
  title = {Rate of Reinforcement Matters in Optimal Foraging Theory},
  author = {Kacelnik, Alejandro and Krebs, John R.},
  year = {1985},
  month = jul,
  volume = {8},
  pages = {340--341},
  issn = {1469-1825, 0140-525X},
  doi = {10.1017/S0140525X00020975},
  abstract = {Rate of reinforcement matters in optimal foraging theory - Volume 8 Issue 2 - Alejandro Kacelnik, John R. Krebs},
  file = {C\:\\Users\\andre\\Zotero\\storage\\XYMEX2GH\\Kacelnik and Krebs - 1985 - Rate of reinforcement matters in optimal foraging .pdf;C\:\\Users\\andre\\Zotero\\storage\\6ZRQXNRE\\A0E7D84F25013263A6A1FCF1369DA133.html},
  journal = {Behavioral and Brain Sciences},
  language = {en},
  number = {2}
}

@article{kacelnik_Risksensitivity_1997,
  title = {Risk-Sensitivity: Crossroads for Theories of Decision-Making},
  shorttitle = {Risk-Sensitivity},
  author = {Kacelnik, A. and Bateson, M.},
  year = {1997},
  month = nov,
  volume = {1},
  pages = {304--309},
  issn = {1364-6613},
  doi = {10.1016/S1364-6613(97)01093-0},
  abstract = {Most actions result in one of a set of possible outcomes. To understand how this uncertainty, or risk, affects animals' decision-making some researchers take a normative approach, asking how an animal should respond to risk if it is maximizing its fitness. Others focus on predicting responses to risk by generalizing from regularities in behavioural data, without reference to cognitive processes. Yet others infer cognitive processes from observed behaviour and ask what actions are predicted when these processes interact with risk. The normative approach (Risk-sensitivity Theory; RST) is unique in predicting a shift in a subject's response to risk as a function of its resource budget, but the predictions of this theory are not yet widely confirmed. In fact, evidence suggests a strong bias towards risk-proneness when delay to reward is risky and risk-aversion when amount of reward is risky, a pattern not readily explained by RST. Extensions of learning theory and of Scalar Expectancy Theory provide process-based explanations for these findings but do not handle preference shifts or provide evolutionary justification for the processes assumed. In this review we defend the view that risk-sensitivity must be studied with theoretical plurality.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\JB4AEBBU\\S1364661397010930.html},
  journal = {Trends in Cognitive Sciences},
  number = {8}
}

@article{kamil_Ecology_1985,
  title = {The {{Ecology}} of {{Foraging Behavior}}: {{Implications}} for {{Animal Learning}} and {{Memory}}},
  shorttitle = {The {{Ecology}} of {{Foraging Behavior}}},
  author = {Kamil, Alan C. and Roitblat, Herbert L.},
  year = {1985},
  volume = {36},
  pages = {141--169},
  doi = {10.1146/annurev.ps.36.020185.001041},
  file = {C\:\\Users\\andre\\Zotero\\storage\\7TVVDX8S\\Kamil and Roitblat - 1985 - The Ecology of Foraging Behavior Implications for.pdf},
  journal = {Annual Review of Psychology},
  number = {1},
  pmid = {3883888}
}

@article{kamil_Evolution_,
  title = {The {{Evolution}} of {{Virtual Ecology}}},
  author = {Kamil, Alan and Bond, Alan B},
  pages = {24},
  file = {C\:\\Users\\andre\\Zotero\\storage\\PPE9SYPJ\\Kamil and Bond - The Evolution of Virtual Ecology.pdf},
  language = {en}
}

@incollection{kamil_Learning_1982,
  title = {Learning and {{Foraging Behavior}}},
  booktitle = {Ontogeny},
  author = {Kamil, Alan C. and Yoerg, Sonja I.},
  editor = {Bateson, P. P. G. and Klopfer, Peter H.},
  year = {1982},
  pages = {325--364},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4615-7578-8_7},
  abstract = {Arguments are presented for the integration of the psychological study of animal learning with the ecological study of foraging behavior. In the first section, several examples from the psychological literature (the matching law, taste-aversion learning, and learning set) are discussed in an attempt to demonstrate how these areas require a more ecological evolutionary approach. Second, current field and laboratory research on foraging behavior is reviewed. We conclude in this section that once ecological foraging research began to concentrate upon the behavior of individual animals, the learning abilities of these animals inevitably became a central issue. Specific methodological and conceptual advantages resulting from the integration of psychology and ecology are discussed in the final section. The chapter concludes with comments on real and perceived obstacles to the occurrence of such interdisciplinary integration in the near future.},
  isbn = {978-1-4615-7578-8},
  keywords = {Changeover Delay,Concurrent Schedule,Forage Behavior,Optimal Forage Theory,Prey Type},
  language = {en},
  series = {Perspectives in {{Ethology}}}
}

@article{kamil_Optimal_1983,
  title = {Optimal {{Foraging Theory}} and the {{Psychology}} of {{Learning}}},
  author = {Kamil, Alan C.},
  year = {1983},
  month = may,
  volume = {23},
  pages = {291--302},
  issn = {1540-7063},
  doi = {10.1093/icb/23.2.291},
  abstract = {Abstract.  The development of optimization theory has made important contributions to the study of animal behavior. But the optimization approach needs to be in},
  file = {C\:\\Users\\andre\\Zotero\\storage\\SEPAMSBM\\Kamil - 1983 - Optimal Foraging Theory and the Psychology of Lear.pdf;C\:\\Users\\andre\\Zotero\\storage\\3KIXGNF3\\302232.html},
  journal = {Integr Comp Biol},
  language = {en},
  number = {2}
}

@article{kerr_Carving_2003,
  title = {Carving the {{Cognitive Niche}}: {{Optimal Learning Strategies}} in {{Homogeneous}} and {{Heterogeneous Environments}}},
  shorttitle = {Carving the {{Cognitive Niche}}},
  author = {Kerr, BENJAMIN and Feldman, MARCUS W.},
  year = {2003},
  month = jan,
  volume = {220},
  pages = {169--188},
  issn = {0022-5193},
  doi = {10.1006/jtbi.2003.3146},
  abstract = {A model learning system is constructed, in which an organism samples behaviors from a behavioral repertoire in response to a stimulus and selects the behavior with the highest payoff. The stimulus and most rewarding behavior may be kept in the organism's long-term memory and reused if the stimulus is encountered again. The value of the memory depends on the reliability of the stimulus, that is, how the corresponding payoffs of behaviors change over time. We describe how the inclusion of memory can increase the optimal sampling size in environments with some stimulus reliability. In addition to using memory to guide behavior, our organism may use information in its memory to choose the stimulus to which it reacts. This choice is influenced by both the organism's memory state and how many stimuli the organism can observe (its sensory capability). The number of sampled behaviors, memory length, and sensory capability are the variables that define the learning strategy. When all stimuli have the same reliability, there appears to be only a single optimal learning strategy. However, when there is heterogeneity in stimulus reliability, multiple locally optimal strategies may exist.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\RPCGFUX7\\S0022519303931468.html},
  journal = {Journal of Theoretical Biology},
  number = {2}
}

@article{kolodny_Evolution_2014,
  title = {The Evolution of Continuous Learning of the Structure of the Environment},
  author = {Kolodny, O. and Edelman, S. and Lotem, A.},
  year = {2014},
  month = jan,
  volume = {11},
  pages = {20131091--20131091},
  issn = {1742-5689, 1742-5662},
  doi = {10.1098/rsif.2013.1091},
  file = {C\:\\Users\\andre\\Zotero\\storage\\H9M75XPW\\20131091.full.pdf;M\:\\storage\\H9M75XPW\\rsif20131091supp1.pdf},
  journal = {Journal of The Royal Society Interface},
  language = {en},
  number = {92}
}

@article{kolodny_Evolution_2015,
  title = {Evolution of Protolinguistic Abilities as a By-Product of Learning to Forage in Structured Environments},
  author = {Kolodny, Oren and Edelman, Shimon and Lotem, Arnon},
  year = {2015},
  month = jul,
  volume = {282},
  pages = {20150353},
  issn = {0962-8452, 1471-2954},
  doi = {10.1098/rspb.2015.0353},
  file = {C\:\\Users\\andre\\Zotero\\storage\\8VMNCMCZ\\20150353.full.pdf;M\:\\storage\\8VMNCMCZ\\rspb20150353supp1.pdf},
  journal = {Proceedings of the Royal Society B: Biological Sciences},
  language = {en},
  number = {1811}
}

@article{kolodny_Evolved_2015,
  title = {Evolved to Adapt: {{A}} Computational Approach to Animal Innovation and Creativity},
  shorttitle = {Evolved to Adapt},
  author = {Kolodny, Oren and Edelman, Shimon and Lotem, Arnon},
  year = {2015},
  month = apr,
  volume = {61},
  pages = {350--368},
  issn = {1674-5507, 2396-9814},
  doi = {10.1093/czoolo/61.2.350},
  abstract = {The production of novel behavioral sequences that gives rise to animal innovation and creativity is one of the most intriguing aspects of behavioral evolution. Numerous studies have recently documented the abundance and diversity of innovative and creative behaviors between and within species, yet the ability to innovate or to act creatively has mainly been described and quantified as a measure of animals' cognitive abilitywithout explicit reference to cognitive mechanismsthat may account for these behaviors. Here we discuss the creative process from a computational point of view and suggest such a mechanistic framework. In light of recent research on human creativity, animal learning, and animal problem solving, we suggest that animal creativity is best understood as the production of context-appropriate novel behavioral sequences, which may be facilitated by the ability to learn the regularities in the environment and to represent them hierarchically, allowing for generalization. We present a cognitive framework that we recently developed, which employs domain-general mechanisms and has been used in the modeling of a range of sequential behaviors, from animal foraging to language acquisition, and apply it to behavioral innovation. In a series of simulations, we show how innovation and creative behavior can be produced by this learning mechanism, as it constructs a network representing the statistical regularities of the environment. We use the simulations to demonstrate the role of particular cognitive parameters in this process and to highlight the effects of the learning dynamics and individual experience on creativity.},
  copyright = {\textcopyright{} 2015 Current Zoology},
  file = {C\:\\Users\\andre\\Zotero\\storage\\Z6EH7TFG\\Kolodny et al. - 2015 - Evolved to adapt A computational approach to anim.pdf;C\:\\Users\\andre\\Zotero\\storage\\FMAUH94U\\350.html},
  journal = {Current Zoology},
  language = {en},
  number = {2}
}

@article{krakauer_Searching_1995,
  title = {Searching and {{Learning}} in a {{Random Environment}}},
  author = {Krakauer, David C. and {Rodr{\'{\i}}guez-Giron{\'e}s}, Miguel A.},
  year = {1995},
  month = dec,
  volume = {177},
  pages = {417--429},
  issn = {0022-5193},
  doi = {10.1006/jtbi.1995.0258},
  abstract = {Area concentrated search provides a means by which foragers may exploit heterogeneities in a resource following a simple rule of thumb which reacts to encounters with that resource by changing search speeds. A model with few parameters is presented. It permits an analysis of optimal searching rules in a random environment. We show that optimal search involves a set of conditional rules that reflect the ``patchiness'' of resource distribution. The optimal area concentrated search strategy is not only a matter of slowing down when encountering a resource, but may involve speeding up when encountering the resource in more uniform environments. The manner in which foragers accumulate information about a resource during searching is analysed as a trade-off between ``identification'' and ``control'' or exploration and exploitation. The value of a period of identification, i.e. a period of learning, is analysed in a fluctuating environment in which the state of the environment is samples from a given distribution following each new foraging bout. The value of learning during searching relates to stochasticity within a bout and variation between bouts. The value of information about the environment within a given foraging bout, and hence the likely value of learning is analysed by comparing optimal strategies with optimal generalist strategies. Information becomes increasingly valuable as resource distributions?!becomes more patchy. Foragers adopting conditional searching rules may manifest type three functional responses (sigmoidal functional response) through an apostatic (positive density dependent) effect. The significance of this response, and learning behaviour on population stability, is briefly discussed.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\8GGP372Q\\S0022519385702585.html},
  journal = {Journal of Theoretical Biology},
  number = {4}
}

@article{kuhl_Sampling_2017,
  title = {Sampling Memory to Make Profitable Choices},
  author = {Kuhl, Brice A and Long, Nicole M},
  year = {2017},
  month = jul,
  volume = {20},
  pages = {903--904},
  issn = {1097-6256},
  journal = {Nat Neurosci},
  number = {7}
}

@article{lakshminaryanan_Endowment_2008,
  title = {Endowment Effect in Capuchin Monkeys},
  author = {Lakshminaryanan, Venkat and Keith Chen, M and Santos, Laurie R},
  year = {2008},
  month = dec,
  volume = {363},
  pages = {3837--3844},
  issn = {0962-8436},
  doi = {10.1098/rstb.2008.0149},
  abstract = {In humans, the capacity for economically rational choice is constrained by a variety of preference biases: humans evaluate gambles relative to arbitrary reference points; weigh losses heavier than equally sized gains; and demand a higher price for owned goods than for equally preferred goods that are not yet owned. To date, however, fewer studies have examined the origins of these biases. Here, we review previous work demonstrating that human economic biases such as loss aversion and reference dependence are shared with an ancestrally related New World primate, the capuchin monkey (Cebus apella). We then examine whether capuchins display an endowment effect in a token-trading task. We identified pairs of treats (fruit discs versus cereal chunks) that were equally preferred by each monkey. When given a chance to trade away their owned fruit discs to obtain the equally valued cereal chunks (or vice versa), however, monkeys required a far greater compensation than the equally preferred treat. We show that these effects are not due to transaction costs or timing issues. These data suggest that biased preferences rely on cognitive systems that are more evolutionarily ancient than previously thought\textemdash and that common evolutionary ancestry shared by humans and capuchins may account for the occurrence of the endowment effect in both species.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\XFRP7SLI\\Lakshminaryanan et al. - 2008 - Endowment effect in capuchin monkeys.pdf},
  journal = {Philos Trans R Soc Lond B Biol Sci},
  number = {1511},
  pmcid = {PMC2581778},
  pmid = {18840573}
}

@article{larkin_Expert_1980,
  title = {Expert and {{Novice Performance}} in {{Solving Physics Problems}}},
  author = {Larkin, Jill and McDermott, John and Simon, Dorothea P. and Simon, Herbert A.},
  year = {1980},
  month = jun,
  volume = {208},
  pages = {1335--1342},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.208.4450.1335},
  abstract = {Although a sizable body of knowledge is prerequisite to expert skill, that knowledge must be indexed by large numbers of patterns that, on recognition, guide the expert in a fraction of a second to relevant parts of the knowledge store. The knowledge forms complex schemata that can guide a problem's interpretation and solution and that constitute a large part of what we call physical intuition.},
  copyright = {\textcopyright{} 1980},
  file = {M\:\\storage\\77J3P243\\simon.pdf;C\:\\Users\\andre\\Zotero\\storage\\77J3P243\\tab-pdf.html},
  journal = {Science},
  language = {en},
  number = {4450},
  pmid = {17775709}
}

@article{lehmann_Evolution_2006,
  title = {The Evolution of Cooperation and Altruism\textendash a General Framework and a Classification of Models},
  author = {Lehmann, L. and Keller, L.},
  year = {2006},
  volume = {19},
  pages = {1365--1376},
  file = {C\:\\Users\\andre\\Zotero\\storage\\RT5ZCAH8\\Lehman_Keller_2006.pdf},
  journal = {J. Evol. Biol.},
  number = {5}
}

@article{leimar_Cooperation_2010,
  title = {Cooperation for Direct Fitness Benefits},
  author = {Leimar, Olof and Hammerstein, Peter},
  year = {2010},
  month = sep,
  volume = {365},
  pages = {2619--2626},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2010.0116},
  abstract = {Studies of the evolution of helping have traditionally used the explanatory frameworks of reciprocity and altruism towards relatives, but recently there has been an increasing interest in other kinds of explanations. We review the success or otherwise of work investigating alternative processes and mechanisms, most of which fall under the heading of cooperation for direct benefits. We evaluate to what extent concepts such as by-product benefits, pseudo-reciprocity, sanctions and partner choice, markets and the build-up of cross-species spatial trait correlations have contributed to the study of the evolution of cooperation. We conclude that these alternative ideas are successful and show potential to further increase our understanding of cooperation. We also bring up the origin and role of common interest in the evolution of cooperation, including the appearance of organisms. We note that there are still unresolved questions about the main processes contributing to the evolution of common interest. Commenting on the broader significance of the recent developments, we argue that they represent a justified balancing of the importance given to different major hypotheses for the evolution of cooperation. This balancing is beneficial because it widens considerably the range of phenomena addressed and, crucially, encourages empirical testing of important theoretical alternatives.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\WN52P22S\\Leimar and Hammerstein - 2010 - Cooperation for direct fitness benefits.pdf;C\:\\Users\\andre\\Zotero\\storage\\KDAPVRGE\\2619.html},
  journal = {Phil. Trans. R. Soc. B},
  keywords = {biological markets,by-product benefits,common interest,Mutualism,pseudo-reciprocity},
  language = {en},
  number = {1553},
  pmid = {20679106}
}

@article{lindholm_DNA_2015,
  title = {{{DNA Dispose}}, but {{Subjects Decide}}. {{Learning}} and the {{Extended Synthesis}}},
  author = {Lindholm, Markus},
  year = {2015},
  month = dec,
  volume = {8},
  pages = {443--461},
  issn = {1875-1342, 1875-1350},
  doi = {10.1007/s12304-015-9242-3},
  abstract = {Adaptation by means of natural selection depends on the ability of populations to maintain variation in heritable traits. According to the Modern Synthesis this variation is sustained by mutations and genetic drift. Epigenetics, evodevo, niche construction and cultural factors have more recently been shown to contribute to heritable variation, however, leading an increasing number of biologists to call for an extended view of speciation and evolution. An additional common feature across the animal kingdom is learning, defined as the ability to change behavior according to novel experiences or skills. Learning constitutes an additional source for phenotypic variation, and change in behavior may induce long lasting shifts in fitness, and hence favor evolutionary novelties. Based on published studies, I demonstrate how learning about food, mate choice and habitats has contributed substantially to speciation in the canonical story of Darwin's finches on the Galapagos Islands. Learning cannot be reduced to genetics, because it demands decisions, which requires a subject. Evolutionary novelties may hence emerge both from shifts in allelic frequencies and from shifts in learned, subject driven behavior. The existence of two principally different sources of variation also prevents the Modern Synthesis from self-referring explanations.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\7WWIV2B5\\Lindholm - 2015 - DNA Dispose, but Subjects Decide. Learning and the.pdf;C\:\\Users\\andre\\Zotero\\storage\\A2KZFUMB\\s12304-015-9242-3.html},
  journal = {Biosemiotics},
  language = {en},
  number = {3}
}

@article{lotem_Coevolution_2012,
  title = {Coevolution of Learning and Data-Acquisition Mechanisms: A Model for Cognitive Evolution},
  shorttitle = {Coevolution of Learning and Data-Acquisition Mechanisms},
  author = {Lotem, A. and Halpern, J. Y.},
  year = {2012},
  month = oct,
  volume = {367},
  pages = {2686--2694},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2012.0213},
  file = {C\:\\Users\\andre\\Zotero\\storage\\99SXEX4K\\Lotem & Halpern 2012 Phil Trans in Animal Minds issue.pdf},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  language = {en},
  number = {1603}
}

@article{lotem_DataAcquisition_2008,
  title = {A {{Data}}-{{Acquisition Model}} for {{Learning}} and {{Cognitive Development}} and {{Its Implications}} for {{Autism}}},
  author = {Lotem, Arnon and Halpern, Joseph Y.},
  year = {2008},
  month = mar,
  abstract = {A data-driven model of learning is proposed, 
where a network of nodes and links is constructed that represents what 
has been heard and observed.   
Autism is viewed as the consequence of a disorder in the data-acquisition 
component of the model---essentially, it is the result of getting an 
``inappropriate'' distribution of data.   
The inappropriate data distribution leads to problems in data 
segmentation, which, in turn leads to a poor network representation. 
It is shown how the model, given 
inappropriate data distributions, can reproduce the main cognitive deficits 
associated with autism, including  
weak central coherence, impaired theory of mind,  
and executive dysfunction. In addition, it is 
shown how the model itself can explain the inappropriate data 
distribution as the result of an inappropriate initial network.  
Finally,  
we discuss the relationships between our model and existing neurological 
models of autism,  
and the possible implications of our model 
for treatment.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\56M5AXHB\\Lotem and Halpern - 2008 - A Data-Acquisition Model for Learning and Cognitiv.pdf;C\:\\Users\\andre\\Zotero\\storage\\RAD7ZHS7\\10178.html},
  language = {en\_US}
}

@article{lotem_Evolution_2017,
  title = {The Evolution of Cognitive Mechanisms in Response to Cultural Innovations},
  author = {Lotem, Arnon and Halpern, Joseph Y. and Edelman, Shimon and Kolodny, Oren},
  year = {2017},
  month = jul,
  volume = {114},
  pages = {7915--7922},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1620742114},
  abstract = {When humans and other animals make cultural innovations, they also change their environment, thereby imposing new selective pressures that can modify their biological traits. For example, there is evidence that dairy farming by humans favored alleles for adult lactose tolerance. Similarly, the invention of cooking possibly affected the evolution of jaw and tooth morphology. However, when it comes to cognitive traits and learning mechanisms, it is much more difficult to determine whether and how their evolution was affected by culture or by their use in cultural transmission. Here we argue that, excluding very recent cultural innovations, the assumption that culture shaped the evolution of cognition is both more parsimonious and more productive than assuming the opposite. In considering how culture shapes cognition, we suggest that a process-level model of cognitive evolution is necessary and offer such a model. The model employs relatively simple coevolving mechanisms of learning and data acquisition that jointly construct a complex network of a type previously shown to be capable of supporting a range of cognitive abilities. The evolution of cognition, and thus the effect of culture on cognitive evolution, is captured through small modifications of these coevolving learning and data-acquisition mechanisms, whose coordinated action is critical for building an effective network. We use the model to show how these mechanisms are likely to evolve in response to cultural phenomena, such as language and tool-making, which are associated with major changes in data patterns and with new computational and statistical challenges.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\T6FFXRWD\\PNAS-2017-Lotem-7915-22.pdf;C\:\\Users\\andre\\Zotero\\storage\\NV237T9Q\\7915.html},
  journal = {PNAS},
  keywords = {cognitive evolution,language evolution,niche construction,Social learning,tool-making},
  language = {en},
  number = {30},
  pmid = {28739938}
}

@article{lotem_Learning_1993,
  title = {Learning to Recognize Nestlings Is Maladaptive for Cuckoo {{Cuculus}} Canorus Hosts},
  author = {Lotem, Arnon},
  year = {1993},
  month = apr,
  volume = {362},
  pages = {743--745},
  issn = {1476-4687},
  doi = {10.1038/362743a0},
  abstract = {THE picture of a tiny passerine host feeding a huge cuckoo nestling challenges evolutionary biologists who explain animal behaviour as adaptive1\textendash 4. Cuckoo eggs sometimes resemble the eggs of the host, but nestlings of the common cuckoo, Cuculus canorus, look very different from the young of the host. The inability of the host to discriminate against such divergent nestlings is especially puzzling as some cuckoo hosts show a finely tuned discrimination ability between eggs5\textendash 8. Here I present a simple model to explain this paradox. The model shows that although learning to recognize eggs is adaptive, learning to recognize nestlings might not be. The mechanism of learned recognition, previously shown to maintain egg recognition, is unlikely to be adaptive for hosts like those of the common cuckoo, in which only the parasitic nestling remains in the nest. The reason that discrimination against parasite nest-lings is not adaptive is that the cost of misimprinting (learning to recognize the parasite nestling as the parents' own) exceeds the benefit of correct learning. The model also explains why nestling discrimination is mostly found in host\textendash parasite systems in which the parasite and the hosts' young are reared together1.},
  copyright = {1993 Nature Publishing Group},
  file = {C\:\\Users\\andre\\Zotero\\storage\\9QW47MMA\\362743a0.html},
  journal = {Nature},
  language = {en},
  number = {6422}
}

@article{ludvig_Associative_2017,
  title = {Associative {{Learning}} from {{Replayed Experience}}},
  author = {Ludvig, Elliot A. and Mirian, Mahdieh S. and Kehoe, E. James and Sutton, Richard S.},
  year = {2017},
  month = jan,
  pages = {100800},
  doi = {10.1101/100800},
  abstract = {We develop an extension of the Rescorla-Wagner model of associative learning. In addition to learning from the current trial, the new model supposes that animals store and replay previous trials, learning from the replayed trials using the same learning rule. This simple idea provides a unified explanation for diverse phenomena that have proved challenging to earlier associative models, including spontaneous recovery, latent inhibition, retrospective revaluation, and trial spacing effects. For example, spontaneous recovery is explained by supposing that the animal replays its previous trials during the interval between extinction and test. These include earlier acquisition trials as well as recent extinction trials, and thus there is a gradual re-acquisition of the conditioned response. We present simulation results for the simplest version of this replay idea, where the trial memory is assumed empty at the beginning of an experiment, all experienced trials are stored and none removed, and sampling from the memory is performed at random. Even this minimal replay model is able to explain the challenging phenomena, illustrating the explanatory power of an associative model enhanced by learning from remembered as well as real experiences.},
  copyright = {\textcopyright{} 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  file = {C\:\\Users\\andre\\Zotero\\storage\\9NPWP8M5\\Ludvig et al. - 2017 - Associative Learning from Replayed Experience.pdf;C\:\\Users\\andre\\Zotero\\storage\\HISFKBJ5\\100800.html},
  journal = {bioRxiv},
  language = {en}
}

@article{ludvig_Evaluating_2012,
  title = {Evaluating the {{TD}} Model of Classical Conditioning},
  author = {Ludvig, Elliot A. and Sutton, Richard S. and Kehoe, E. James},
  year = {2012},
  month = sep,
  volume = {40},
  pages = {305--319},
  issn = {1543-4508},
  doi = {10.3758/s13420-012-0082-6},
  abstract = {The temporal-difference (TD) algorithm from reinforcement learning provides a simple method for incrementally learning predictions of upcoming events. Applied to classical conditioning, TD models suppose that animals learn a real-time prediction of the unconditioned stimulus (US) on the basis of all available conditioned stimuli (CSs). In the TD model, similar to other error-correction models, learning is driven by prediction errors\textemdash the difference between the change in US prediction and the actual US. With the TD model, however, learning occurs continuously from moment to moment and is not artificially constrained to occur in trials. Accordingly, a key feature of any TD model is the assumption about the representation of a CS on a moment-to-moment basis. Here, we evaluate the performance of the TD model with a heretofore unexplored range of classical conditioning tasks. To do so, we consider three stimulus representations that vary in their degree of temporal generalization and evaluate how the representation influences the performance of the TD model on these conditioning tasks.},
  journal = {Learning \& Behavior},
  number = {3}
}

@article{mackintosh_Theory_,
  title = {A Theory of Attention: {{Variations}} in the Associability of Stimuli with Reinforcement},
  shorttitle = {A Theory of Attention},
  author = {Mackintosh, N. J.},
  volume = {82},
  pages = {276--298},
  issn = {0033-295X},
  doi = {http://dx.doi.org/10.1037/h0076778},
  abstract = {Review of the literature indicates that, according to theories of selective attention, learning about a stimulus depends on attending to that stimulus; this is represented in 2-stage models by saying that Ss switch in analyzers as well as learning stimulus-response associations. It is argued that this assumption, however, is equally well represented in a formal model by the incorporation of a stimulus-specific learning-rate parameter, a, into the equations describing changes in the associative strength of stimuli. Previous theories of selective attention have also assumed that (a) Ss learn to attend to and ignore relevant and irrelevant stimuli (i.e., that a may increase or decrease depending on the correlation of a stimulus with reinforcement); and (b) there is an inverse relationship between the probabilities of attending to different stimuli (i.e., that an increase in a to one stimulus is accompanied by a decrease in a to others). The first assumption has been used to explain the phenomena of acquired distinctiveness and dimensional transfer, the second to explain those of overshadowing and blocking. It is argued that although the first assumption is justified by the data, the second is not: Overshadowing and blocking are better explained by the choice of an appropriate rule for changing a, such that a decreases to stimuli that signal no change from the probability of reinforcement predicted by other stimuli. (65 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  copyright = {\textcopyright{} 1975, American Psychological Association},
  file = {C\:\\Users\\andre\\Zotero\\storage\\FIW9DZKF\\Mackintosh - A theory of attention Variations in the associabi.pdf},
  journal = {Psychological Review},
  keywords = {Associative Processes (principal),Learning Rate (principal),Learning Theory (principal),Reinforcement (principal),Selective Attention (principal)},
  language = {Anglais},
  number = {4}
}

@article{mackintosh_Theory_1975,
  title = {A Theory of Attention: {{Variations}} in the Associability of Stimuli with Reinforcement.},
  shorttitle = {A Theory of Attention},
  author = {Mackintosh, Nicholas J.},
  year = {1975},
  volume = {82},
  pages = {276},
  file = {C\:\\Users\\andre\\Zotero\\storage\\IKAFAL8S\\mackintosh1975.pdf},
  journal = {Psychological review},
  number = {4}
}

@article{maclean_Evolution_2014,
  title = {The Evolution of Self-Control},
  author = {MacLean, Evan L. and Hare, Brian and Nunn, Charles L. and Addessi, Elsa and Amici, Federica and Anderson, Rindy C. and Aureli, Filippo and Baker, Joseph M. and Bania, Amanda E. and Barnard, Allison M. and Boogert, Neeltje J. and Brannon, Elizabeth M. and Bray, Emily E. and Bray, Joel and Brent, Lauren J. N. and Burkart, Judith M. and Call, Josep and Cantlon, Jessica F. and Cheke, Lucy G. and Clayton, Nicola S. and Delgado, Mikel M. and DiVincenti, Louis J. and Fujita, Kazuo and Herrmann, Esther and Hiramatsu, Chihiro and Jacobs, Lucia F. and Jordan, Kerry E. and Laude, Jennifer R. and Leimgruber, Kristin L. and Messer, Emily J. E. and Moura, Antonio C. de A. and Ostoji{\'c}, Ljerka and Picard, Alejandra and Platt, Michael L. and Plotnik, Joshua M. and Range, Friederike and Reader, Simon M. and Reddy, Rachna B. and Sandel, Aaron A. and Santos, Laurie R. and Schumann, Katrin and Seed, Amanda M. and Sewall, Kendra B. and Shaw, Rachael C. and Slocombe, Katie E. and Su, Yanjie and Takimoto, Ayaka and Tan, Jingzhi and Tao, Ruoting and van Schaik, Carel P. and Vir{\'a}nyi, Zs{\'o}fia and Visalberghi, Elisabetta and Wade, Jordan C. and Watanabe, Arii and Widness, Jane and Young, Julie K. and Zentall, Thomas R. and Zhao, Yini},
  year = {2014},
  month = may,
  volume = {111},
  pages = {E2140-E2148},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1323533111},
  abstract = {Cognition presents evolutionary research with one of its greatest challenges. Cognitive evolution has been explained at the proximate level by shifts in absolute and relative brain volume and at the ultimate level by differences in social and dietary complexity. However, no study has integrated the experimental and phylogenetic approach at the scale required to rigorously test these explanations. Instead, previous research has largely relied on various measures of brain size as proxies for cognitive abilities. We experimentally evaluated these major evolutionary explanations by quantitatively comparing the cognitive performance of 567 individuals representing 36 species on two problem-solving tasks measuring self-control. Phylogenetic analysis revealed that absolute brain volume best predicted performance across species and accounted for considerably more variance than brain volume controlling for body mass. This result corroborates recent advances in evolutionary neurobiology and illustrates the cognitive consequences of cortical reorganization through increases in brain volume. Within primates, dietary breadth but not social group size was a strong predictor of species differences in self-control. Our results implicate robust evolutionary relationships between dietary breadth, absolute brain volume, and self-control. These findings provide a significant first step toward quantifying the primate cognitive phenome and explaining the process of cognitive evolution.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\LVRZKL9Q\\MacLean et al. - 2014 - The evolution of self-control.pdf;C\:\\Users\\andre\\Zotero\\storage\\PTDW58SS\\E2140.html},
  journal = {PNAS},
  keywords = {behavior,comparative methods,executive function,inhibitory control,psychology},
  language = {en},
  number = {20},
  pmid = {24753565}
}

@article{masuda_Theoretical_2009,
  title = {A {{Theoretical Analysis}} of {{Temporal Difference Learning}} in the {{Iterated Prisoner}}'s {{Dilemma Game}}},
  author = {Masuda, Naoki and Ohtsuki, Hisashi},
  year = {2009},
  month = nov,
  volume = {71},
  pages = {1818--1850},
  issn = {0092-8240, 1522-9602},
  doi = {10.1007/s11538-009-9424-8},
  abstract = {Direct reciprocity is a chief mechanism of mutual cooperation in social dilemma. Agents cooperate if future interactions with the same opponents are highly likely. Direct reciprocity has been explored mostly by evolutionary game theory based on natural selection. Our daily experience tells, however, that real social agents including humans learn to cooperate based on experience. In this paper, we analyze a reinforcement learning model called temporal difference learning and study its performance in the iterated Prisoner's Dilemma game. Temporal difference learning is unique among a variety of learning models in that it inherently aims at increasing future payoffs, not immediate ones. It also has a neural basis. We analytically and numerically show that learners with only two internal states properly learn to cooperate with retaliatory players and to defect against unconditional cooperators and defectors. Four-state learners are more capable of achieving a high payoff against various opponents. Moreover, we numerically show that four-state learners can learn to establish mutual cooperation for sufficiently small learning rates.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\F879RVSW\\Masuda and Ohtsuki - 2009 - A Theoretical Analysis of Temporal Difference Lear.pdf;C\:\\Users\\andre\\Zotero\\storage\\2HFV43FF\\Masuda and Ohtsuki - 2009 - A Theoretical Analysis of Temporal Difference Lear.html},
  journal = {Bull. Math. Biol.},
  language = {en},
  number = {8}
}

@book{maynard-smith_Evolution_1982,
  title = {Evolution and the {{Theory}} of {{Games}}},
  author = {{Maynard-Smith}, John},
  year = {1982},
  month = dec,
  edition = {1 edition},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge ; New York}},
  abstract = {In this 1982 book, the theory of games, first developed to analyse economic behaviour, is modified so that it can be applied to evolving populations. John Maynard Smith's concept of an evolutionarily stable strategy is relevant whenever the best thing for an animal or plant to do depends on what others are doing. The theory leads to testable predictions about the evolution of behaviour, of sex and genetic systems, and of growth and life history patterns. This book contains a full account of the theory, and of the data relevant to it. The account is aimed at senior undergraduate and graduate students, teachers and research workers in animal behaviour, population genetics and evolutionary biology. The book will also be of interest to mathematicians and game theorists; the mathematics has been largely confined to appendixes so that the main text may be easily followed by biologists.},
  isbn = {978-0-521-28884-2},
  language = {English}
}

@book{maynardsmith_Major_1998,
  title = {The {{Major Transitions}} in {{Evolution}}},
  author = {Maynard Smith, John and Szathm{\'a}ry, Eors},
  year = {1998},
  month = feb,
  publisher = {{Oxford University Press}},
  address = {{Oxford, England}},
  isbn = {0-19-850294-X}
}

@article{mcauliffe_Psychology_2015,
  title = {The Psychology of Cooperation in Animals: An Ecological Approach},
  shorttitle = {The Psychology of Cooperation in Animals},
  author = {McAuliffe, K. and Thornton, A.},
  year = {2015},
  month = jan,
  volume = {295},
  pages = {23--35},
  issn = {1469-7998},
  doi = {10.1111/jzo.12204},
  abstract = {There has been a recent push to study the psychological processes supporting cooperation in nonhuman animals. However, progress has been limited thus far due to differences in approaches between psychologists and behavioral ecologists. Although the former tend to use controlled experiments to pinpoint precise cognitive mechanisms, these experiments often lack ecological validity. In contrast, behavioral ecologists seek to understand the adaptive function of cooperative behavior of animals in the wild but typically neglect the underlying psychological mechanisms. Here we appraise and integrate evidence from these two approaches to understand the potential cognitive solutions to four fundamental challenges that animals face during cooperative interactions under natural conditions: (1) when to cooperate; (2) with whom to cooperate; (3) what to do in cooperative interactions; (4) how much to contribute to cooperation. We argue that an ecologically motivated approach is critical to understanding the psychological mechanisms of cooperation and how these mechanisms evolve.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\FW95UKC4\\McAuliffe and Thornton - 2015 - The psychology of cooperation in animals an ecolo.pdf;C\:\\Users\\andre\\Zotero\\storage\\BMBEC4XB\\abstract.html},
  journal = {J Zool},
  keywords = {cognitive mechanisms,cooperation,ecological approach,evolutionary function},
  language = {en},
  number = {1}
}

@article{mcclelland_Letting_2010,
  title = {Letting Structure Emerge: Connectionist and Dynamical Systems Approaches to Cognition},
  shorttitle = {Letting Structure Emerge},
  author = {McClelland, James L. and Botvinick, Matthew M. and Noelle, David C. and Plaut, David C. and Rogers, Timothy T. and Seidenberg, Mark S. and Smith, Linda B.},
  year = {2010},
  month = aug,
  volume = {14},
  pages = {348--356},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2010.06.002},
  abstract = {Connectionist and dynamical systems approaches explain human thought, language and behavior in terms of the emergent consequences of a large number of simple noncognitive processes. We view the entities that serve as the basis for structured probabilistic approaches as abstractions that are occasionally useful but often misleading: they have no real basis in the actual processes that give rise to linguistic and cognitive abilities or to the development of these abilities. Although structured probabilistic approaches can be useful in determining what would be optimal under certain assumptions, we propose that connectionist, dynamical systems, and related approaches, which focus on explaining the mechanisms that give rise to cognition, will be essential in achieving a full understanding of cognition and development.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\X2V9G3KC\\S1364661310001245.html},
  journal = {Trends in Cognitive Sciences},
  number = {8}
}

@article{mcnair_Stochastic_1981,
  title = {A Stochastic Foraging Model with Predator Training Effects. {{II}}. {{Optimal}} Diets},
  author = {McNair, James N.},
  year = {1981},
  month = apr,
  volume = {19},
  pages = {147--162},
  issn = {0040-5809},
  doi = {10.1016/0040-5809(81)90014-9},
  abstract = {Standard optimal diet models require that a predator's behavior while searching for food does not change in response to experiences with individual prey. There is evidence for rapid and reversible changes in feeding behavior caused by as few as one or two prey encounters. When these ``training effects'' occur, a given prey type is more likely to be captured next if it was the last type with which the predator had experience. This is not compatible with the standard foraging model. I present a stochastic model which incorporates predator training effects, and three types of training are explored: training in the ability to detect prey (search image formation), training in the probability of succeeding in an attempted capture, and training in the time to pursue, capture, and eat prey. The main result is that all three types of training can result in optimal diets which do not obey the standard optimal diet rules. Conditions under which these rules will suffice are discussed.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\KPMZC5DM\\0040580981900149.html},
  journal = {Theoretical Population Biology},
  number = {2}
}

@article{mcnamara_Integrating_2009,
  title = {Integrating Function and Mechanism},
  author = {McNamara, John M. and Houston, Alasdair I.},
  year = {2009},
  month = dec,
  volume = {24},
  pages = {670--675},
  issn = {0169-5347},
  doi = {10.1016/j.tree.2009.05.011},
  abstract = {Behavioural ecology often makes the assumption that animals can respond flexibly by adopting the optimal behaviour for each circumstance. However, as ethologists have long known, behaviour is determined by mechanisms that are not optimal in every circumstance. As we discuss here, we believe that it is necessary to integrate these separate traditions by considering the evolution of mechanisms, an approach referred to as `Evo-mecho'. This integration is timely because there is a growing awareness of the importance of environmental complexity in shaping behaviour; there are established and effective computational procedures for simulating evolution and there is rapidly increasing knowledge of the neuronal basis of decision-making. Although behavioural ecologists have built complex models of optimal behaviour in simple environments, we argue that they need to focus on simple mechanisms that perform well in complex environments.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\ZDA99S7S\\S0169-5347(09)00202-X.html},
  journal = {Trends in Ecology \& Evolution},
  language = {English},
  number = {12},
  pmid = {19683827}
}

@article{miller_Magical_1956,
  title = {The Magical Number Seven, plus or Minus Two: {{Some}} Limits on Our Capacity for Processing Information.},
  author = {Miller, George A.},
  year = {1956},
  volume = {63},
  pages = {81},
  file = {C\:\\Users\\andre\\Zotero\\storage\\83LTCWHR\\miller1956.pdf;M\:\\storage\\83LTCWHR\\miller1956.pdf},
  journal = {Psychological review},
  number = {2}
}

@article{mondragon_Associative_2017,
  title = {Associative {{Learning Should Go Deep}}},
  author = {Mondrag{\'o}n, Esther and Alonso, Eduardo and Kokkola, Niklas},
  year = {2017},
  month = jun,
  issn = {1364-6613},
  doi = {10.1016/j.tics.2017.06.001},
  abstract = {Conditioning, how animals learn to associate two or more events, is one of the most influential paradigms in learning theory. It is nevertheless unclear how current models of associative learning can accommodate complex phenomena without ad hoc representational assumptions. We propose to embrace deep neural networks to negotiate this problem.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\WWAXHGVX\\S1364661317301250.html},
  journal = {Trends in Cognitive Sciences},
  keywords = {associative learning,deep neural networks}
}

@article{mongillo_Misbehavior_2014,
  title = {The {{Misbehavior}} of {{Reinforcement Learning}}},
  author = {Mongillo, Gianluigi and Shteingart, Hanan and Loewenstein, Yonatan},
  year = {2014},
  month = apr,
  volume = {102},
  pages = {528--541},
  issn = {0018-9219, 1558-2256},
  doi = {10.1109/JPROC.2014.2307022},
  abstract = {Organisms modify their behavior in response to observed patterns of choice behavior. We conclude by identiits consequences, a phenomenon referred to as operant fying some of the important challenges to a comprehensive learning. The computational principles and neural mechanisms theory of operant learning.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\AEVI29DX\\Mongillo et al. - 2014 - The Misbehavior of Reinforcement Learning.pdf},
  journal = {Proceedings of the IEEE},
  language = {en},
  number = {4}
}

@article{mongillo_Misbehavior_2014a,
  title = {The {{Misbehavior}} of {{Reinforcement Learning}}},
  author = {Mongillo, G. and Shteingart, H. and Loewenstein, Y.},
  year = {2014},
  month = apr,
  volume = {102},
  pages = {528--541},
  issn = {0018-9219},
  doi = {10.1109/JPROC.2014.2307022},
  abstract = {Organisms modify their behavior in response to its consequences, a phenomenon referred to as operant learning. The computational principles and neural mechanisms underlying operant learning are a subject of extensive experimental and theoretical investigations. Theoretical approaches largely rely on concepts and algorithms from reinforcement learning. The dominant view is that organisms maintain a value function, that is, a set of estimates of the cumulative future rewards associated with the different behavioral options. These values are then used to select actions. Learning in this framework results from the update of these values depending on experience of the consequences of past actions. An alternative view questions the applicability of such a computational scheme to many real-life situations. Instead, it posits that organisms exploit the intrinsic variability in their action-selection mechanism(s) to modify their behavior, e.g., via stochastic gradient ascent, without the need of an explicit representation of values. In this review, we compare these two approaches in terms of their computational power and flexibility, their putative neural correlates, and, finally, in terms of their ability to account for behavior as observed in repeated-choice experiments. We discuss the successes and failures of these alternative approaches in explaining the observed patterns of choice behavior. We conclude by identifying some of the important challenges to a comprehensive theory of operant learning.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\SHW6CLGK\\6767062.html},
  journal = {Proceedings of the IEEE},
  keywords = {action-selection mechanism,behavioral options,Behavioral science,Computational intelligence,Computational modeling,computational power,computational principles,Decision making,flexibility,gradient methods,Gradient methods,intrinsic variability,learning (artificial intelligence),Learning (artificial intelligence),learning systems,Machine learning,Markov decision process,Markov processes,neural mechanisms,neural nets,neural networks,Neural networks,Neurons,operant learning,putative neural correlates,Reinforcement learning,reinforcement learning misbehavior,stochastic gradient ascent,Transient analysis},
  number = {4}
}

@article{montague_Framework_1996,
  title = {A Framework for Mesencephalic Dopamine Systems Based on Predictive {{Hebbian}} Learning},
  author = {Montague, P. R. and Dayan, P. and Sejnowski, T. J.},
  year = {1996},
  month = mar,
  volume = {16},
  pages = {1936--1947},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.16-05-01936.1996},
  abstract = {We develop a theoretical framework that shows how mesencephalic dopamine systems could distribute to their targets a signal that represents information about future expectations. In particular, we show how activity in the cerebral cortex can make predictions about future receipt of reward and how fluctuations in the activity levels of neurons in diffuse dopamine systems above and below baseline levels would represent errors in these predictions that are delivered to cortical and subcortical targets. We present a model for how such errors could be constructed in a real brain that is consistent with physiological results for a subset of dopaminergic neurons located in the ventral tegmental area and surrounding dopaminergic neurons. The theory also makes testable predictions about human choice behavior on a simple decision-making task. Furthermore, we show that, through a simple influence on synaptic plasticity, fluctuations in dopamine release can act to change the predictions in an appropriate manner.},
  copyright = {\textcopyright{} 1996 by Society for Neuroscience},
  file = {C\:\\Users\\andre\\Zotero\\storage\\LETYTTP3\\Montague et al. - 1996 - A framework for mesencephalic dopamine systems bas.pdf;C\:\\Users\\andre\\Zotero\\storage\\SQ9WT3MT\\1936.html},
  journal = {J. Neurosci.},
  language = {en},
  number = {5},
  pmid = {8774460}
}

@article{morris_Evolution_2017,
  title = {Evolution of Flexibility and Rigidity in Retaliatory Punishment},
  author = {Morris, Adam and MacGlashan, James and Littman, Michael L. and Cushman, Fiery},
  year = {2017},
  month = sep,
  pages = {201704032},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1704032114},
  file = {C\:\\Users\\andre\\Zotero\\storage\\YUU38I5S\\1704032114.full.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en}
}

@article{nasser_Dopamine_2017,
  title = {The {{Dopamine Prediction Error}}: {{Contributions}} to {{Associative Models}} of {{Reward Learning}}},
  shorttitle = {The {{Dopamine Prediction Error}}},
  author = {Nasser, Helen M. and Calu, Donna J. and Schoenbaum, Geoffrey and Sharpe, Melissa J.},
  year = {2017},
  volume = {8},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2017.00244},
  abstract = {Phasic activity of midbrain dopamine neurons is currently thought to encapsulate the prediction-error signal described in Sutton and Barto's (1981) model-free reinforcement learning algorithm. This phasic signal is thought to contain information about the quantitative value of reward, which transfers to the reward-predictive cue after learning. This is argued to endow the reward-predictive cue with the value inherent in the reward, motivating behavior towards cues signaling the presence of reward. Yet theoretical and empirical research has implicated prediction-error signaling in learning that extends far beyond a transfer of quantitative value to a reward-predictive cue. Here, we review the research which demonstrates the complexity of how dopaminergic prediction errors facilitate learning. After briefly discussing the literature demonstrating that phasic dopaminergic signals can act in the manner described by Sutton and Barto (1981), we consider how these signals may also influence attentional processing across multiple attentional systems in distinct brain circuits. Then, we discuss how prediction errors encode and promote the development of context-specific associations between cues and rewards. Finally, we consider recent evidence that shows dopaminergic activity contains information about causal relationships between cues and rewards that reflect information garnered from rich associative models of the world that can be adapted in the absence of direct experience. In discussing this research we hope to support the expansion of how dopaminergic prediction errors are thought to contribute to the learning process beyond the traditional concept of transferring quantitative value.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\C77BKXY2\\Nasser et al. - 2017 - The Dopamine Prediction Error Contributions to As.pdf},
  journal = {Front. Psychol.},
  keywords = {associative learning,Attention,Dopamine,model-based learning,Prediction error},
  language = {English}
}

@article{niv_Reinforcement_2009,
  title = {Reinforcement Learning in the Brain},
  author = {Niv, Yael},
  year = {2009},
  month = jun,
  volume = {53},
  pages = {139--154},
  issn = {00222496},
  doi = {10.1016/j.jmp.2008.12.005},
  abstract = {A wealth of research focuses on the decision-making processes that animals and humans employ when selecting actions in the face of reward and punishment. Initially such work stemmed from psychological investigations of conditioned behavior, and explanations of these in terms of computational models. Increasingly, analysis at the computational level has drawn on ideas from reinforcement learning, which provide a normative framework within which decision-making can be analyzed. More recently, the fruits of these extensive lines of research have made contact with investigations into the neural basis of decision making. Converging evidence now links reinforcement learning to specific neural substrates, assigning them precise computational roles. Specifically, electrophysiological recordings in behaving animals and functional imaging of human decision-making have revealed in the brain the existence of a key reinforcement learning signal, the temporal difference reward prediction error. Here, we first introduce the formal reinforcement learning framework. We then review the multiple lines of evidence linking reinforcement learning to the function of dopaminergic neurons in the mammalian midbrain and to more recent data from human imaging experiments. We further extend the discussion to aspects of learning not associated with phasic dopamine signals, such as learning of goal-directed responding that may not be dopamine-dependent, and learning about the vigor (or rate) with which actions should be performed that has been linked to tonic aspects of dopaminergic signaling. We end with a brief discussion of some of the limitations of the reinforcement learning framework, highlighting questions for future research.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\QVMHEA84\\Niv - 2009 - Reinforcement learning in the brain.pdf},
  journal = {Journal of Mathematical Psychology},
  language = {en},
  number = {3}
}

@article{noe_Biological_1994a,
  title = {Biological Markets: Supply and Demand Determine the Effect of Partner Choice in Cooperation, Mutualism and Mating},
  shorttitle = {Biological Markets},
  author = {No{\"e}, Ronald and Hammerstein, Peter},
  year = {1994},
  month = jul,
  volume = {35},
  pages = {1--11},
  issn = {0340-5443, 1432-0762},
  doi = {10.1007/BF00167053},
  abstract = {The formation of collaborating pairs by individuals belonging to two different classes occurs in the contexts of reproduction and intea-specific cooperation as well as of inter-specific mutualism. There is potential for partner choice and for competition for access to preferred partners in all three contexts. These selective forces have long been recognised as important in sexual selection, but their impact is not yet appreciated in cooperative and mutualistic systems. The formation of partnerships between members of different classes has much in common with the conclusion of trade agreements in human markets with two classes of traders, like producers and consumers, or employers and employees. Similar game-theoretical models can be used to predict the behaviour of rational traders in human markets and the evolutionarily stable strategies used in biological markets. We present a formal model in which the influence of the market mechanism on selection is made explicit. We restrict ourselves to biological markets in which: (1) Individuals do not compete over access to partners in an agonistic manner, but rather by outcompeting each other in those aspects that are preferred by the choosing party. (2) The commodity the partner has to offer cannot be obtained by the use of force, but requires the consent of the partner. These two restrictions ensure a dominant role for partner choice in the formation of partnerships. In a biological market model the decision to cooperate is based on the comparison between the offers of several potential partners, rather than on the behaviour of a single potential partner, as is implicitly assumed in currently accepted models of cooperation. In our example the members of one class A offer a commodity of fixed value in exchange for a commodity of variable value supplied by the other class, B. We show that when the B-class outnumbers the A-class sufficiently and the cost for the A-class to sample the offers of the B-class are low, the choosiness of the A-class will lead to selection for the supply of high value commodities by the B-class (Fig. 3a). Under the same market conditions, but with a high sampling cost this may still be the evolutionariy stable outcome, but another pair of strategies proves to be stable too: relaxed choosiness of class A coupled with low value commodities supplied by class B (Fig. 3b). We give a number of examples of mating, cooperative and mutualistic markets that resemble the low sampling cost situation depicted in Fig. 3a.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\TN5H42JI\\Noë and Hammerstein - 1994 - Biological markets supply and demand determine th.pdf;C\:\\Users\\andre\\Zotero\\storage\\IA983A2P\\BF00167053.html},
  journal = {Behav Ecol Sociobiol},
  keywords = {Behavioural Sciences,Cooperation Mutualism,ess,Market genes,sexual selection,Zoology},
  language = {en},
  number = {1}
}

@article{oconnell_Vertebrate_2011,
  title = {The {{Vertebrate}} Mesolimbic Reward System and Social Behavior Network: {{A}} Comparative Synthesis},
  shorttitle = {The {{Vertebrate}} Mesolimbic Reward System and Social Behavior Network},
  author = {O'Connell, Lauren A. and Hofmann, Hans A.},
  year = {2011},
  month = dec,
  volume = {519},
  pages = {3599--3639},
  issn = {1096-9861},
  doi = {10.1002/cne.22735},
  abstract = {All animals evaluate the salience of external stimuli and integrate them with internal physiological information into adaptive behavior. Natural and sexual selection impinge on these processes, yet our understanding of behavioral decision-making mechanisms and their evolution is still very limited. Insights from mammals indicate that two neural circuits are of crucial importance in this context: the social behavior network and the mesolimbic reward system. Here we review evidence from neurochemical, tract-tracing, developmental, and functional lesion/stimulation studies that delineates homology relationships for most of the nodes of these two circuits across the five major vertebrate lineages: mammals, birds, reptiles, amphibians, and teleost fish. We provide for the first time a comprehensive comparative analysis of the two neural circuits and conclude that they were already present in early vertebrates. We also propose that these circuits form a larger social decision-making (SDM) network that regulates adaptive behavior. Our synthesis thus provides an important foundation for understanding the evolution of the neural mechanisms underlying reward processing and behavioral regulation. J. Comp. Neurol. 519:3599\textendash 3639, 2011. \textcopyright{} 2011 Wiley-Liss, Inc.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\8DI2SZHV\\O'Connell and Hofmann - 2011 - The Vertebrate mesolimbic reward system and social.pdf;C\:\\Users\\andre\\Zotero\\storage\\PQZNPXTB\\abstract.html},
  journal = {J. Comp. Neurol.},
  keywords = {amphibian,bird,comparative neuroanatomy,limbic system,neural circuits,reptile,reward system,social behavior,social behavior network,teleost},
  language = {en},
  number = {18}
}

@article{olsson_Limits_1997,
  title = {The {{Limits}} to {{Reproductive Output}}: {{Offspring Size Versus Number}} in the {{Sand Lizard}} ({{Lacerta}} Agilis)},
  shorttitle = {The {{Limits}} to {{Reproductive Output}}},
  author = {Olsson, M. and Shine, R.},
  year = {1997},
  month = jan,
  volume = {149},
  pages = {179--188},
  issn = {0003-0147, 1537-5323},
  doi = {10.1086/285985},
  file = {C\:\\Users\\andre\\Zotero\\storage\\DSAZV88D\\285985.pdf},
  journal = {The American Naturalist},
  language = {en},
  number = {1}
}

@article{pearce_Model_1980,
  title = {A Model for {{Pavlovian}} Learning: Variations in the Effectiveness of Conditioned but Not of Unconditioned Stimuli.},
  shorttitle = {A Model for {{Pavlovian}} Learning},
  author = {Pearce, John M. and Hall, Geoffrey},
  year = {1980},
  volume = {87},
  pages = {532},
  file = {C\:\\Users\\andre\\Zotero\\storage\\3ASQEIGF\\PearceHall1980.pdf;M\:\\storage\\3ASQEIGF\\Pearce and Hall - 1980 - A model for Pavlovian learning variations in the .pdf},
  journal = {Psychological review},
  number = {6}
}

@article{pearce_Similarity_1994,
  title = {Similarity and Discrimination: A Selective Review and a Connectionist Model.},
  shorttitle = {Similarity and Discrimination},
  author = {Pearce, John M.},
  year = {1994},
  volume = {101},
  pages = {587},
  file = {C\:\\Users\\andre\\Zotero\\storage\\RGMRJGFA\\pearce1994.pdf},
  journal = {Psychological review},
  number = {4}
}

@article{pepperberg_Can_2014,
  title = {Can Grey Parrots ({{Psittacus}} Erithacus) Succeed on a "Complex" Foraging Task Failed by Nonhuman Primates ({{Pan}} Troglodytes, {{Pongo}} Abelii, {{Sapajus}} Apella) but Solved by Wrasse Fish ({{Labroides}} Dimidiatus)?},
  author = {Pepperberg, Irene M. and Hartsfield, Leigh Ann},
  year = {2014},
  month = aug,
  volume = {128},
  pages = {298--306},
  issn = {1939-2087},
  doi = {10.1037/a0036205},
  abstract = {Linking specific cognitive abilities of nonhuman species on a laboratory task to their evolutionary history-ecological niche can be a fruitful exercise in comparative psychology. Crucial issues, however, are the choice of task, the specific conditions of the task, and possibly the subjects' understanding or interpretation of the task. Salwiczek et al. (2012) compared cleaner wrasse fish (Labroides dimidaitus) to several nonhuman primate species (capuchins, Sapajus paella; chimpanzees, Pan troglodytes; orangutans, Pongo abelii) on a task purportedly related to the ecological demands of the fish, but not necessarily of the nonhuman primates; fish succeeded whereas almost all of the nonhuman primates that were tested failed. We replicated the two-choice paradigm of the task with three Grey parrots (Psittacus erithacus), whose ecology, evolutionary history, and cortical capacity are arguably more like those of nonhuman primates than fish. Greys succeeded at levels more like fish than all the nonhuman primates, suggesting possible alternative explanations for their success. Fish and nonhuman primate subjects also experienced a reversal of the initial conditions to test for generalization: Greys were similarly tested; they performed more like fish and capuchins (who now succeeded) than the apes (who continued to fail).},
  journal = {J Comp Psychol},
  keywords = {Animals,Behavior; Animal,Cebus,Pan troglodytes,Parrots,Perciformes,Pongo abelii,Reversal Learning,Species Specificity},
  language = {eng},
  number = {3},
  pmid = {24798239}
}

@article{plonsky_Reliance_2015,
  title = {Reliance on Small Samples, the Wavy Recency Effect, and Similarity-Based Learning.},
  author = {Plonsky, Ori and Teodorescu, Kinneret and Erev, Ido},
  year = {2015},
  volume = {122},
  pages = {621--647},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/a0039413},
  file = {C\:\\Users\\andre\\Zotero\\storage\\84JMX2VG\\Plonsky, Teodorescu, and Erev, 2015.pdf},
  journal = {Psychological Review},
  language = {en},
  number = {4}
}

@book{puterman_Markov_2014,
  title = {{Markov Decision Processes: Discrete Stochastic Dynamic Programming}},
  shorttitle = {{Markov Decision Processes}},
  author = {Puterman, Martin L.},
  year = {2014},
  month = aug,
  publisher = {{John Wiley \& Sons}},
  abstract = {The Wiley-Interscience Paperback Series consists of selected books that have been made more accessible to consumers in an effort to increase global appeal and general circulation. With these new unabridged softcover volumes, Wiley hopes to extend the lives of these works by making them available to future generations of statisticians, mathematicians, and scientists. "This text is unique in bringing together so many results hitherto found only in part in other texts and papers. . . . The text is fairly self-contained, inclusive of some basic mathematical results needed, and provides a rich diet of examples, applications, and exercises. The bibliographical material at the end of each chapter is excellent, not only from a historical perspective, but because it is valuable for researchers in acquiring a good perspective of the MDP research potential." \textemdash Zentralblatt fur Mathematik ". . . it is of great value to advanced-level students, researchers, and professional practitioners of this field to have now a complete volume (with more than 600 pages) devoted to this topic. . . . Markov Decision Processes: Discrete Stochastic Dynamic Programming represents an up-to-date, unified, and rigorous treatment of theoretical and computational aspects of discrete-time Markov decision processes." \textemdash Journal of the American Statistical Association},
  googlebooks = {VvBjBAAAQBAJ},
  isbn = {978-1-118-62587-3},
  keywords = {Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes},
  language = {de},
  series = {{Wilwy series in probability and statistics}}
}

@article{quinones_Reinforcement_2019,
  title = {Reinforcement {{Learning Theory Reveals}} the {{Cognitive Requirements}} for {{Solving}} the {{Cleaner Fish Market Task}}},
  author = {Qui{\~n}ones, Andr{\'e}s E. and Leimar, Olof and Lotem, Arnon and Bshary, Redouan},
  year = {2019},
  month = dec,
  pages = {000--000},
  publisher = {{The University of Chicago Press}},
  issn = {0003-0147},
  doi = {10.1086/707519},
  abstract = {Learning is an adaptation that allows individuals to respond to environmental stimuli in ways that improve their reproductive outcomes. The degree of sophistication in learning mechanisms potentially explains variation in behavioral responses. Here, we present a model of learning that is inspired by documented intra- and interspecific variation in the performance of a simultaneous two-choice task, the biological market task. The task presents a problem that cleaner fish often face in nature: choosing between two client types, one that is willing to wait for inspection and one that may leave if ignored. The cleaner's choice hence influences the future availability of clients (i.e., it influences food availability). We show that learning the preference that maximizes food intake requires subjects to represent in their memory different combinations of pairs of client types rather than just individual client types. In addition, subjects need to account for future consequences of actions, either by estimating expected long-term reward or by experiencing a client leaving as a penalty (negative reward). Finally, learning is influenced by the absolute and relative abundance of client types. Thus, cognitive mechanisms and ecological conditions jointly explain intra- and interspecific variation in the ability to learn the adaptive response.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\RFMIKZ2F\\58766Supplement.pdf;C\:\\Users\\andre\\Zotero\\storage\\RFMIKZ2F\\Quiñones et al. - 2019 - Reinforcement Learning Theory Reveals the Cognitiv.pdf;C\:\\Users\\andre\\Zotero\\storage\\93H5ZMEJ\\707519.html},
  journal = {The American Naturalist}
}

@article{real_Animal_1991,
  title = {Animal Choice Behavior and the Evolution of Cognitive Architecture},
  author = {Real, L. A.},
  year = {1991},
  month = aug,
  volume = {253},
  pages = {980--986},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1887231},
  abstract = {Animals process sensory information according to specific computational rules and, subsequently, form representations of their environments that form the basis for decisions and choices. The specific computational rules used by organisms will often be evolutionarily adaptive by generating higher probabilities of survival, reproduction, and resource acquisition. Experiments with enclosed colonies of bumblebees constrained to foraging on artificial flowers suggest that the bumblebee's cognitive architecture is designed to efficiently exploit floral resources from spatially structured environments given limits on memory and the neuronal processing of information. A non-linear relationship between the biomechanics of nectar extraction and rates of net energetic gain by individual bees may account for sensitivities to both the arithmetic mean and variance in reward distributions in flowers. Heuristic rules that lead to efficient resource exploitation may also lead to subjective misperception of likelihoods. Subjective probability formation may then be viewed as a problem in pattern recognition subject to specific sampling schemes and memory constraints.},
  copyright = {\textcopyright{} 1991},
  file = {C\:\\Users\\andre\\Zotero\\storage\\AK55VFHC\\980.html},
  journal = {Science},
  language = {en},
  number = {5023},
  pmid = {1887231}
}

@article{real_Animal_1991a,
  title = {Animal Choice Behavior and the Evolution of Cognitive Architecture},
  author = {Real, L. A.},
  year = {1991},
  month = aug,
  volume = {253},
  pages = {980--986},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1887231},
  abstract = {Animals process sensory information according to specific computational rules and, subsequently, form representations of their environments that form the basis for decisions and choices. The specific computational rules used by organisms will often be evolutionarily adaptive by generating higher probabilities of survival, reproduction, and resource acquisition. Experiments with enclosed colonies of bumblebees constrained to foraging on artificial flowers suggest that the bumblebee's cognitive architecture is designed to efficiently exploit floral resources from spatially structured environments given limits on memory and the neuronal processing of information. A non-linear relationship between the biomechanics of nectar extraction and rates of net energetic gain by individual bees may account for sensitivities to both the arithmetic mean and variance in reward distributions in flowers. Heuristic rules that lead to efficient resource exploitation may also lead to subjective misperception of likelihoods. Subjective probability formation may then be viewed as a problem in pattern recognition subject to specific sampling schemes and memory constraints.},
  copyright = {\textcopyright{} 1991},
  file = {C\:\\Users\\andre\\Zotero\\storage\\K22FNM3U\\real 1991.pdf;C\:\\Users\\andre\\Zotero\\storage\\VK572GZD\\real1991.pdf},
  journal = {Science},
  language = {en},
  number = {5023},
  pmid = {1887231}
}

@article{real_Cognitive_1993,
  title = {Toward a Cognitive Ecology},
  author = {Real, Leslie A.},
  year = {1993},
  month = nov,
  volume = {8},
  pages = {413--417},
  issn = {0169-5347},
  doi = {10.1016/0169-5347(93)90044-P},
  abstract = {The emergence of cognitive psychology as the dominant approach to understanding human behaviors and actions acknowledges the importance of internal mental operations in generating specific behavioral responses to sets of external stimuli. Traditional behaviorist interpretations that rely primarily on external inputs as the precursors of action have been largely replaced by cognitive approaches. The main intent of this article is to outline the major areas that require exploration if we wish to apply fully the principles and insight of cognitive science to behavioral ecology.},
  file = {C\:\\Users\\a.quinones\\Zotero\\storage\\AU9JLPRW\\real1993.pdf;C\:\\Users\\andre\\Zotero\\storage\\AU9JLPRW\\016953479390044P.html},
  journal = {Trends in Ecology \& Evolution},
  number = {11}
}

@incollection{rescorla_Theory_1972,
  title = {A Theory of {{Pavlovian}} Conditioning: Variations in the Effectiveness of Reinforcement and Non-Reinforcement},
  booktitle = {Classical Conditioning {{II}}: Current Research and Theory},
  author = {Rescorla, R. A. and Wagner, A. R. A.},
  editor = {Black, Abraham H. and Prokasy, William Frederick},
  year = {1972},
  publisher = {{Appleton-Century-Crofts}},
  address = {{New York}},
  file = {M\:\\storage\\Rescorla & Wagner 1972.pdf}
}

@incollection{robson_Evolutionary_2011,
  title = {The {{Evolutionary Foundations}} of {{Preferences}}},
  booktitle = {Handbook of {{Social Economics}}},
  author = {Robson, Arthur J. and Samuelson, Larry},
  editor = {Benhabib, Jess and Bisin, Alberto and Jackson, Matthew O.},
  year = {2011},
  month = jan,
  volume = {1},
  pages = {221--310},
  publisher = {{North-Holland}},
  doi = {10.1016/B978-0-444-53187-2.00007-3},
  abstract = {This paper surveys recent work on the evolutionary origins of preferences. We are especially interested in the circumstances under which evolution would push preferences away from the self-interested perfectly-rational expected utility maximization of classical economic theory in order to incorporate environmental or social considerations. JEL Codes: D0, D8},
  file = {C\:\\Users\\andre\\Zotero\\storage\\WTJ4RKNY\\Robson and Samuelson - 2011 - Chapter 7 - The Evolutionary Foundations of Prefer.pdf;C\:\\Users\\andre\\Zotero\\storage\\M76KT4UF\\B9780444531872000073.html},
  keywords = {Discounting,Evolution,Evolution of Preferences,Group Selection,Hyperbolic Discounting,Preferences,Relative Consumption,Risk,Status}
}

@article{rowe_Measuring_2014,
  title = {Measuring Variation in Cognition},
  author = {Rowe, Candy and Healy, Susan D.},
  year = {2014},
  month = jan,
  volume = {25},
  pages = {1287--1292},
  issn = {1045-2249},
  doi = {10.1093/beheco/aru090},
  abstract = {Across a range of disciplines, researchers are becoming increasingly interested in studying the variation in cognitive abilities found within populations. Behavioral ecology is no exception: the pursuit to understand the evolution of cognition has lead to a rapidly expanding literature that uses various tasks to measure individuals' cognitive abilities. While this is an exciting time, we are concerned that without being clearer as to the cognitive abilities under test it will be difficult to design appropriate experiments and the interpretation of the data may be unsound. The aim of this review is 3-fold: 1) to highlight problems with designing tasks for measuring individual variation in cognitive abilities and interpreting their outcomes; 2) to increase awareness that noncognitive factors can cause variation in performance among individuals; and 3) to question the theoretical basis for thinking that performance in any cognitive task should necessarily correlate with a measure of fitness. Our take-home message is that variability in performance in cognitive tasks does not necessarily demonstrate individual variation in cognitive ability, and that we need to both design more stringent cognitive tests and be more cautious in their interpretation.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\AQ6RWURB\\Rowe and Healy - 2014 - Measuring variation in cognition.pdf;C\:\\Users\\andre\\Zotero\\storage\\CSNZM3JA\\Measuring-variation-in-cognition.html},
  journal = {Behav Ecol},
  number = {6}
}

@article{sakai_ActorCritic_2007,
  title = {The {{Actor}}-{{Critic Learning Is Behind}} the {{Matching Law}}: {{Matching Versus Optimal Behaviors}}},
  shorttitle = {The {{Actor}}-{{Critic Learning Is Behind}} the {{Matching Law}}},
  author = {Sakai, Yutaka and Fukai, Tomoki},
  year = {2007},
  month = nov,
  volume = {20},
  pages = {227--251},
  issn = {0899-7667},
  doi = {10.1162/neco.2008.20.1.227},
  abstract = {The ability to make a correct choice of behavior from various options is crucial for animals' survival. The neural basis for the choice of behavior has been attracting growing attention in research on biological and artificial neural systems. Alternative choice tasks with variable ratio (VR) and variable interval (VI) schedules of reinforcement have often been employed in studying decision making by animals and humans. In the VR schedule task, alternative choices are reinforced with different probabilities, and subjects learn to select the behavioral response rewarded more frequently. In the VI schedule task, alternative choices are reinforced at different average intervals independent of the choice frequencies, and the choice behavior follows the so-called matching law. The two policies appear robustly in subjects' choice of behavior, but the underlying neural mechanisms remain unknown. Here, we show that these seemingly different policies can appear from a common computational algorithm known as actor-critic learning. We present experimentally testable variations of the VI schedule in which the matching behavior gives only a suboptimal solution to decision making and show that the actor-critic system exhibits the matching behavior in the steady state of the learning even when the matching behavior is suboptimal. However, it is found that the matching behavior can earn approximately the same reward as the optimal one in many practical situations.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\4T2HU67Q\\neco.2008.20.1.html},
  journal = {Neural Computation},
  number = {1}
}

@article{salwiczek_Adult_2012,
  title = {Adult {{Cleaner Wrasse Outperform Capuchin Monkeys}}, {{Chimpanzees}} and {{Orang}}-Utans in a {{Complex Foraging Task Derived}} from {{Cleaner}} \textendash{} {{Client Reef Fish Cooperation}}},
  author = {Salwiczek, Lucie H. and Pr{\'e}t{\^o}t, Laurent and Demarta, Lanila and Proctor, Darby and Essler, Jennifer and Pinto, Ana I. and Wismer, Sharon and Stoinski, Tara and Brosnan, Sarah F. and Bshary, Redouan},
  year = {2012},
  month = nov,
  volume = {7},
  pages = {e49068},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0049068},
  abstract = {The insight that animals' cognitive abilities are linked to their evolutionary history, and hence their ecology, provides the framework for the comparative approach. Despite primates renowned dietary complexity and social cognition, including cooperative abilities, we here demonstrate that cleaner wrasse outperform three primate species, capuchin monkeys, chimpanzees and orang-utans, in a foraging task involving a choice between two actions, both of which yield identical immediate rewards, but only one of which yields an additional delayed reward. The foraging task decisions involve partner choice in cleaners: they must service visiting client reef fish before resident clients to access both; otherwise the former switch to a different cleaner. Wild caught adult, but not juvenile, cleaners learned to solve the task quickly and relearned the task when it was reversed. The majority of primates failed to perform above chance after 100 trials, which is in sharp contrast to previous studies showing that primates easily learn to choose an action that yields immediate double rewards compared to an alternative action. In conclusion, the adult cleaners' ability to choose a superior action with initially neutral consequences is likely due to repeated exposure in nature, which leads to specific learned optimal foraging decision rules.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\VVPF6PF9\\Salwiczek et al. - 2012 - Adult Cleaner Wrasse Outperform Capuchin Monkeys, .pdf;C\:\\Users\\andre\\Zotero\\storage\\E4JC5CK7\\article.html},
  journal = {PLOS ONE},
  keywords = {Animal sociality,Apes,Chimpanzees,Food,foraging,Human learning,learning,Primates},
  number = {11}
}

@article{schmajuk_Experimental_,
  title = {Experimental Challenges to Theories of Classical Conditioning: {{Application}} of an Attentional Model of Storage and Retrieval},
  shorttitle = {Experimental Challenges to Theories of Classical Conditioning},
  author = {Schmajuk, Nestor A. and Larrauri, Jos{\'e} A.},
  volume = {32},
  pages = {1--20},
  issn = {0097-7403},
  doi = {http://dx.doi.org/10.1037/0097-7403.32.1.1},
  abstract = {Several studies have recently challenged the accuracy of traditional models of classical conditioning that account for some experimental data in terms of a storage deficit. Among other results, it has been reported that extinction of the blocking or overshadowing stimulus results in the recovery of the response to the blocked or overshadowed stimulus, backward blocking shows spontaneous recovery, extinction of the training context results in the recovery from latent inhibition, interposing a delay between conditioning and testing in latent inhibition increases latent inhibition, and latent inhibition antagonizes overshadowing. An existing neural network model of classical conditioning (N. A. Schmajuk, Y. Lam, \& J. A. Gray, 1996), which includes an attentional mechanism controlling both storage and retrieval of associations, is able to quantitatively describe these results. (PsycINFO Database Record (c) 2016 APA, all rights reserved) (Source: journal abstract)},
  copyright = {\textcopyright{} 2006, American Psychological Association},
  file = {C\:\\Users\\andre\\Zotero\\storage\\FN8B9EJ8\\Schmajuk and Larrauri - Experimental challenges to theories of classical c.pdf},
  journal = {Journal of Experimental Psychology: Animal Behavior Processes},
  keywords = {Attention (principal),Classical Conditioning (principal),Latent Inhibition (principal),Models (principal),Neural networks},
  language = {Anglais},
  number = {1}
}

@article{schmajuk_Latent_1996,
  title = {Latent Inhibition: A Neural Network Approach},
  shorttitle = {Latent Inhibition},
  author = {Schmajuk, N. A. and Gray, J. A. and Lam, Y. W.},
  year = {1996},
  month = jul,
  volume = {22},
  pages = {321--349},
  issn = {0097-7403},
  journal = {J Exp Psychol Anim Behav Process},
  keywords = {Association Learning,attention,Brain,Conditioning; Classical,Humans,Neural Inhibition,Neural Networks (Computer)},
  language = {eng},
  number = {3},
  pmid = {8691162}
}

@article{schultz_Neuronal_2015,
  title = {Neuronal {{Reward}} and {{Decision Signals}}: {{From Theories}} to {{Data}}},
  shorttitle = {Neuronal {{Reward}} and {{Decision Signals}}},
  author = {Schultz, Wolfram},
  year = {2015},
  month = jul,
  volume = {95},
  pages = {853--951},
  issn = {0031-9333},
  doi = {10.1152/physrev.00023.2014},
  abstract = {Rewards are crucial objects that induce learning, approach behavior, choices, and emotions. Whereas emotions are difficult to investigate in animals, the learning function is mediated by neuronal reward prediction error signals which implement basic constructs of reinforcement learning theory. These signals are found in dopamine neurons, which emit a global reward signal to striatum and frontal cortex, and in specific neurons in striatum, amygdala, and frontal cortex projecting to select neuronal populations. The approach and choice functions involve subjective value, which is objectively assessed by behavioral choices eliciting internal, subjective reward preferences. Utility is the formal mathematical characterization of subjective value and a prime decision variable in economic choice theory. It is coded as utility prediction error by phasic dopamine responses. Utility can incorporate various influences, including risk, delay, effort, and social interaction. Appropriate for formal decision mechanisms, rewards are coded as object value, action value, difference value, and chosen value by specific neurons. Although all reward, reinforcement, and decision variables are theoretical constructs, their neuronal signals constitute measurable physical implementations and as such confirm the validity of these concepts. The neuronal reward signals provide guidance for behavior while constraining the free will to act.},
  journal = {Physiol Rev},
  number = {3},
  pmcid = {PMC4491543},
  pmid = {26109341}
}

@article{servan-schreiber_Learning_1990,
  title = {Learning Artificial Grammars with Competitive Chunking.},
  author = {{Servan-Schreiber}, Emile and Anderson, John R.},
  year = {1990},
  volume = {16},
  pages = {592},
  file = {C\:\\Users\\andre\\Zotero\\storage\\SHPAF66V\\servanschreiber1990.pdf},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  number = {4}
}

@article{sharpe_Dopamine_2017,
  title = {Dopamine Transients Are Sufficient and Necessary for Acquisition of Model-Based Associations},
  author = {Sharpe, Melissa J and Chang, Chun Yun and Liu, Melissa A. and Batchelor, Hannah M. and Mueller, Lauren E. and Jones, Joshua L and Niv, Yael and Schoenbaum, Geoffrey},
  year = {2017},
  month = may,
  volume = {20},
  pages = {735--742},
  issn = {1097-6256},
  doi = {10.1038/nn.4538},
  abstract = {Associative learning is driven by prediction errors. Dopamine transients correlate with these errors, which current interpretations limit to endowing cues with a scalar quantity reflecting the value of future rewards. Here, we tested whether dopamine might act more broadly to support learning of an associative model of the environment. Using sensory preconditioning, we show that prediction errors underlying stimulus-stimulus learning can be blocked behaviorally and reinstated by optogenetically activating dopamine neurons. We further show that suppressing the firing of these neurons across t transition prevents normal stimulus-stimulus learning. These results establish that the acquisition of model-based information about transitions between non-rewarding events is also driven by prediction errors, and that contrary to existing canon, dopamine transients are both sufficient and necessary to support this type of learning. Our findings open new possibilities for how these biological signals might support associative learning in the mammalian brain in these and other contexts.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\SYUDL4IR\\Sharpe et al. - 2017 - Dopamine transients are sufficient and necessary f.pdf},
  journal = {Nat Neurosci},
  number = {5},
  pmcid = {PMC5413864},
  pmid = {28368385}
}

@inproceedings{shelton_Balancing_2001,
  title = {Balancing Multiple Sources of Reward in Reinforcement Learning},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Shelton, Christian R.},
  year = {2001},
  pages = {1082--1088},
  file = {C\:\\Users\\andre\\Zotero\\storage\\2S5XCQPR\\1831-balancing-multiple-sources-of-reward-in-reinforcement-learning.pdf}
}

@book{shettleworth_Cognition_2009,
  title = {Cognition, {{Evolution}}, and {{Behavior}}},
  author = {Shettleworth, Sara J.},
  year = {2009},
  month = dec,
  edition = {2 edition},
  publisher = {{Oxford University Press}},
  address = {{Oxford ; New York}},
  abstract = {How do animals perceive the world, learn, remember, search for food or mates, communicate, and find their way around? Do any nonhuman animals count, imitate one another, use a language, or have a culture? What are the uses of cognition in nature and how might it have evolved? What is the current status of Darwin's claim that other species share the same "mental powers" as humans, but to different degrees? In this completely revised second edition of Cognition, Evolution, and Behavior, Sara Shettleworth addresses these questions, among others, by integrating findings from psychology, behavioral ecology, and ethology in a unique and wide-ranging synthesis of theory and research on animal cognition, in the broadest sense--from species-specific adaptations of vision in fish and associative learning in rats to discussions of theory of mind in chimpanzees, dogs, and ravens. She reviews the latest research on topics such as episodic memory, metacognition, and cooperation and other-regarding behavior in animals, as well as recent theories about what makes human cognition unique.In every part of this new edition, Shettleworth incorporates findings and theoretical approaches that have emerged since the first edition was published in 1998. The chapters are now organized into three sections: Fundamental Mechanisms (perception, learning, categorization, memory), Physical Cognition (space, time, number, physical causation), and Social Cognition (social knowledge, social learning, communication). Shettleworth has also added new chapters on evolution and the brain and on numerical cognition, and a new chapter on physical causation that integrates theories of instrumental behavior with discussions of foraging, planning, and tool using.},
  isbn = {978-0-19-531984-2},
  language = {English}
}

@article{simon_How_1974,
  title = {How {{Big Is}} a {{Chunk}}?: {{By}} Combining Data from Several Experiments, a Basic Human Memory Unit Can Be Identified and Measured},
  shorttitle = {How {{Big Is}} a {{Chunk}}?},
  author = {Simon, Herbert A.},
  year = {1974},
  month = feb,
  volume = {183},
  pages = {482--488},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.183.4124.482},
  abstract = {I have explored some of the interactions between research on higher mental processes over the past decade or two and laboratory experiments on simpler cognitive processes. I have shown that, by viewing experimentation in a parameter-estimating paradigm instead of a hypothesis-testing paradigm, one can obtain much more information from experiments\textemdash information that, combined with contemporary theoretical models of the cognitive processes, has implications for human performance on tasks quite different from those of the original experiments.
The work of identifying and measuring the basic parameters of the human information processing system has just begun, but already important information has been gained. The psychological reality of the chunk has been fairly well demonstrated, and the chunk capacity of short-term memory has been shown to be in the range of five to seven. Fixation of information in longterm memory has been shown to take about 5 or 10 seconds per chunk.
Some other "magical numbers" have been estimated\textemdash for example, visual scanning speeds and times required for simple grammatical transformations\textemdash and no doubt others remain to be discovered. But even the two basic constants discussed in this article\textemdash short-term memory capacity and rate of fixation in long-term memory\textemdash organize, systematize, and explain a wide range of findings, about both simple tasks and more complex cognitive performances that have been reported in the psychological literature over the past 50 years or more.},
  copyright = {1974 by the American Association for the Advancement of Science},
  file = {M\:\\storage\\EHK7BG94\\da1caf92074dbae832f848a35a648cd38298.pdf;C\:\\Users\\andre\\Zotero\\storage\\EHK7BG94\\482.html},
  journal = {Science},
  language = {en},
  number = {4124},
  pmid = {17773029}
}

@article{singh_Intrinsically_2010a,
  title = {Intrinsically {{Motivated Reinforcement Learning}}: {{An Evolutionary Perspective}}},
  shorttitle = {Intrinsically {{Motivated Reinforcement Learning}}},
  author = {Singh, S. and Lewis, R. L. and Barto, A. G. and Sorg, J.},
  year = {2010},
  month = jun,
  volume = {2},
  pages = {70--82},
  issn = {1943-0604},
  doi = {10.1109/TAMD.2010.2051031},
  abstract = {There is great interest in building intrinsic motivation into artificial systems using the reinforcement learning framework. Yet, what intrinsic motivation may mean computationally, and how it may differ from extrinsic motivation, remains a murky and controversial subject. In this paper, we adopt an evolutionary perspective and define a new optimal reward framework that captures the pressure to design good primary reward functions that lead to evolutionary success across environments. The results of two computational experiments show that optimal primary reward signals may yield both emergent intrinsic and extrinsic motivation. The evolutionary perspective and the associated optimal reward framework thus lead to the conclusion that there are no hard and fast features distinguishing intrinsic and extrinsic reward computationally. Rather, the directness of the relationship between rewarding behavior and evolutionary success varies along a continuum.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\CWL98EPI\\5471106.html},
  journal = {IEEE Transactions on Autonomous Mental Development},
  keywords = {artificial system,Cognitive science,Computer science,Genetic algorithms,History,Humans,intrinsic motivation,Intrinsic motivation,learning,learning (artificial intelligence),optimal primary reward signal,Psychology,reinforcement learning,reward functions,Signal resolution,System performance},
  number = {2}
}

@book{staddon_Adaptive_2016,
  title = {Adaptive {{Behavior}} and {{Learning}}},
  author = {Staddon, J. E. R.},
  year = {2016},
  month = mar,
  edition = {2 edition},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  abstract = {Every day at about 4:30, Jazz, a Hungarian Vizsla dog, leaps up on the sofa and looks out for his owner who always comes home at 5:00. He doesn't need an internal clock because he has an acute sense of smell that allows him to measure how long his master has been absent. Explaining complex behavior in simple ways, this book is a fascinating exploration of the evolution, development and processes of learning in animals. Now in its second edition, there is increased emphasis on development, evolution and dynamics; new accounts of taxic orientation, reflex induction, habituation and operant learning in organisms; more discussion of spatial learning and the processes underlying it; expanded chapters on choice and completely new chapters on molar laws, classical conditioning theories and comparative cognition. J. E. R. Staddon provides a definitive summary of contemporary theoretical understanding suitable for graduates and advanced undergraduates.},
  isbn = {978-1-107-44290-0},
  language = {English}
}

@article{staddon_Operant_2003,
  title = {Operant {{Conditioning}}},
  author = {Staddon, J. E. R. and Cerutti, D. T.},
  year = {2003},
  volume = {54},
  pages = {115--144},
  doi = {10.1146/annurev.psych.54.101601.145124},
  abstract = {Operant behavior is behavior ``controlled'' by its consequences. In practice, operant conditioning is the study of reversible behavior maintained by reinforcement schedules. We review empirical studies and theoretical approaches to two large classes of operant behavior: interval timing and choice. We discuss cognitive versus behavioral approaches to timing, the ``gap'' experiment and its implications, proportional timing and Weber's law, temporal dynamics and linear waiting, and the problem of simple chain-interval schedules. We review the long history of research on operant choice: the matching law, its extensions and problems, concurrent chain schedules, and self-control. We point out how linear waiting may be involved in timing, choice, and reinforcement schedules generally. There are prospects for a unified approach to all these areas.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\6M2TZJVM\\Staddon and Cerutti - 2003 - Operant Conditioning.pdf},
  journal = {Annual Review of Psychology},
  number = {1},
  pmid = {12415075}
}

@article{sutherland_Configural_1989,
  title = {Configural Association Theory: {{The}} Role of the Hippocampal Formation in Learning, Memory, and Amnesia},
  shorttitle = {Configural Association Theory},
  author = {Sutherland, R. J. and Rudy, J. W.},
  year = {1989},
  month = jun,
  volume = {17},
  pages = {129--144},
  issn = {0889-6313},
  doi = {10.3758/BF03337828},
  abstract = {It is proposed that the hippocampal formation makes a unique contribution to memory by providing the neural basis for the initial acquisition and storage of configural associations among events. A distinction is made between two kinds of memory processes: a simple associative process, which does not depend on the hippocampal formation, and a configural associative process, which does. The simple associative system records the organism's experiences as changes in the strength of associations between elementary stimulus events. The configural associative system combines the representations of elementary stimulus events to construct unique representations and allows for the formation of associations between these configural representations and other elementary representations. In the present paper, the results of two experiments designed to test predictions of our theory are described. We then illustrate how the theory can be applied to explain a wide range of impairments that have been observed when learning and memory tasks have been employed to assess the effect of hippocampal formation damage. These include tasks that measure place learning, recognition memory, latent inhibition, serial-compound conditioning, discrimination-reversal learning, and stimulus-selection processes. The relationship of our position to some other views of hippocampal function is discussed, and we conclude with suggestions for future research.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\C6CL7WPK\\Sutherland and Rudy - 1989 - Configural association theory The role of the hip.pdf;C\:\\Users\\andre\\Zotero\\storage\\D53BZVNY\\BF03337828.html},
  journal = {Psychobiology},
  language = {en},
  number = {2}
}

@book{sutton_Reinforcement_1998,
  title = {Reinforcement {{Learning}}: {{An Introduction}}},
  shorttitle = {Reinforcement {{Learning}}},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  year = {1998},
  month = mar,
  edition = {1St Edition edition},
  publisher = {{A Bradford Book}},
  address = {{Cambridge, Mass}},
  abstract = {Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In  Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability.The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.},
  file = {C\:\\Users\\a.quinones\\Zotero\\storage\\RLbook2018.pdf},
  isbn = {978-0-262-19398-6},
  language = {English}
}

@book{sutton_Reinforcement_2018,
  title = {Reinforcement {{Learning}}: {{An Introduction}}},
  shorttitle = {Reinforcement {{Learning}}},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  editor = {Bach, Francis},
  year = {2018},
  month = nov,
  edition = {second edition edition},
  publisher = {{A Bradford Book}},
  address = {{Cambridge, MA}},
  abstract = {The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence.Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics.Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.},
  file = {C\:\\Users\\a.quinones\\Zotero\\storage\\RLbook2018.pdf},
  isbn = {978-0-262-03924-6},
  language = {English}
}

@article{sznajder_How_2012,
  title = {How {{Adaptive Learning Affects Evolution}}: {{Reviewing Theory}} on the {{Baldwin Effect}}},
  shorttitle = {How {{Adaptive Learning Affects Evolution}}},
  author = {Sznajder, B. and Sabelis, M. W. and Egas, M.},
  year = {2012},
  month = sep,
  volume = {39},
  pages = {301--310},
  issn = {0071-3260, 1934-2845},
  doi = {10.1007/s11692-011-9155-2},
  abstract = {We review models of the Baldwin effect, i.e., the hypothesis that adaptive learning (i.e., learning to improve fitness) accelerates genetic evolution of the phenotype. Numerous theoretical studies scrutinized the hypothesis that a non-evolving ability of adaptive learning accelerates evolution of genetically determined behavior. However, their results are conflicting in that some studies predict an accelerating effect of learning on evolution, whereas others show a decelerating effect. We begin by describing the arguments underlying the hypothesis on the Baldwin effect and identify the core argument: adaptive learning influences the rate of evolution because it changes relative fitness of phenotypes. Then we analyze the theoretical studies of the Baldwin effect with respect to their model of adaptive learning and discuss how their contrasting results can be explained from differences in (1) the ways in which the effect of adaptive learning on the phenotype is modeled, (2) the assumptions underlying the function used to quantify fitness and (3) the time scale at which the evolutionary rate is measured. We finish by reviewing the specific assumptions used by the theoretical studies of the Baldwin effect and discuss the evolutionary implications for cases where these assumptions do not hold.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\AG8AV3HH\\Sznajder et al. - 2012 - How Adaptive Learning Affects Evolution Reviewing.pdf;C\:\\Users\\andre\\Zotero\\storage\\H6I9HWM9\\s11692-011-9155-2.html},
  journal = {Evol Biol},
  language = {en},
  number = {3}
}

@article{takahashi_Silencing_2008,
  title = {Silencing the {{Critics}}: {{Understanding}} the {{Effects}} of {{Cocaine Sensitization}} on {{Dorsolateral}} and {{Ventral Striatum}} in the {{Context}} of an {{Actor}}/{{Critic Model}}},
  shorttitle = {Silencing the {{Critics}}},
  author = {Takahashi, Yuji and Schoenbaum, Geoffrey and Niv, Yael},
  year = {2008},
  month = jul,
  volume = {2},
  pages = {86--99},
  issn = {1662-4548},
  doi = {10.3389/neuro.01.014.2008},
  abstract = {A critical problem in daily decision making is how to choose actions now in order to bring about rewards later. Indeed, many of our actions have long-term consequences, and it is important to not be myopic in balancing the pros and cons of different options, but rather to take into account both immediate and delayed consequences of actions. Failures to do so may be manifest as persistent, maladaptive decision-making, one example of which is addiction where behavior seems to be driven by the immediate positive experiences with drugs, despite the delayed adverse consequences. A recent study by Takahashi et al. () investigated the effects of cocaine sensitization on decision making in rats and showed that drug use resulted in altered representations in the ventral striatum and the dorsolateral striatum, areas that have been implicated in the neural instantiation of a computational solution to optimal long-term actions selection called the Actor/Critic framework. In this Focus article we discuss their results and offer a computational interpretation in terms of drug-induced impairments in the Critic. We first survey the different lines of evidence linking the subparts of the striatum to the Actor/Critic framework, and then suggest two possible scenarios of breakdown that are suggested by Takahashi et al.'s () data. As both are compatible with the current data, we discuss their different predictions and how these could be empirically tested in order to further elucidate (and hopefully inch towards curing) the neural basis of drug addiction.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\8S8MP8NT\\Takahashi et al. - 2008 - Silencing the Critics Understanding the Effects o.pdf},
  journal = {Front Neurosci},
  number = {1},
  pmcid = {PMC2570074},
  pmid = {18982111}
}

@article{thornton_Individual_2012,
  title = {Individual Variation in Cognitive Performance: Developmental and Evolutionary Perspectives},
  shorttitle = {Individual Variation in Cognitive Performance},
  author = {Thornton, Alex and Lukas, Dieter},
  year = {2012},
  month = oct,
  volume = {367},
  pages = {2773--2783},
  doi = {10.1098/rstb.2012.0214},
  abstract = {Animal cognition experiments frequently reveal striking individual variation but rarely consider its causes and largely ignore its potential consequences. Studies often focus on a subset of high-performing subjects, sometimes viewing evidence from a single individual as sufficient to demonstrate the cognitive capacity of a species. We argue that the emphasis on demonstrating species-level cognitive capacities detracts from the value of individual variation in understanding cognitive development and evolution. We consider developmental and evolutionary interpretations of individual variation and use meta-analyses of data from published studies to examine predictors of individual performance. We show that reliance on small sample sizes precludes robust conclusions about individual abilities as well as inter- and intraspecific differences. We advocate standardization of experimental protocols and pooling of data between laboratories to improve statistical rigour. Our analyses show that cognitive performance is influenced by age, sex, rearing conditions and previous experience. These effects limit the validity of comparative analyses unless developmental histories are taken into account, and complicate attempts to understand how cognitive traits are expressed and selected under natural conditions. Further understanding of cognitive evolution requires efforts to elucidate the heritability of cognitive traits and establish whether elevated cognitive performance confers fitness advantages in nature.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\RIGSFR65\\Thornton Alex and Lukas Dieter - 2012 - Individual variation in cognitive performance dev.pdf;C\:\\Users\\andre\\Zotero\\storage\\4SAEILIB\\rstb.2012.html},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  number = {1603}
}

@article{torney_Specialization_2010,
  title = {Specialization and Evolutionary Branching within Migratory Populations},
  author = {Torney, Colin J. and Levin, Simon A. and Couzin, Iain D.},
  year = {2010},
  month = nov,
  volume = {107},
  pages = {20394--20399},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1014316107},
  abstract = {Understanding the mechanisms that drive specialization and speciation within initially homogeneous populations is a fundamental challenge for evolutionary theory. It is an issue of relevance for significant open questions in biology concerning the generation and maintenance of biodiversity, the origins of reciprocal cooperation, and the efficient division of labor in social or colonial organisms. Several mathematical frameworks have been developed to address this question and models based on evolutionary game theory or the adaptive dynamics of phenotypic mutation have demonstrated the emergence of polymorphic, specialized populations. Here we focus on a ubiquitous biological phenomenon, migration. Individuals in our model may evolve the capacity to detect and follow an environmental cue that indicates a preferred migration route. The strategy space is defined by the level of investment in acquiring personal information about this route or the alternative tendency to follow the direction choice of others. The result is a relation between the migratory process and a game theoretic dynamic that is generally applicable to situations where information may be considered a public good. Through the use of an approximation of social interactions, we demonstrate the emergence of a stable, polymorphic population consisting of an uninformed subpopulation that is dependent upon a specialized group of leaders. The branching process is classified using the techniques of adaptive dynamics.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\8M3H84V4\\Torney et al. - 2010 - Specialization and evolutionary branching within m.pdf;C\:\\Users\\andre\\Zotero\\storage\\B277YZWR\\20394.html},
  journal = {PNAS},
  keywords = {collective behavior,evolutionary dynamics,social information},
  language = {en},
  number = {47},
  pmid = {21059935}
}

@article{triki_Biological_2019,
  title = {Biological Market Effects Predict Cleaner Fish Strategic Sophistication},
  author = {Triki, Zegni and Wismer, Sharon and Rey, Olivia and Ann Binning, Sandra and Levorato, Elena and Bshary, Redouan},
  year = {2019},
  month = nov,
  volume = {30},
  pages = {1548--1557},
  publisher = {{Oxford Academic}},
  issn = {1045-2249},
  doi = {10.1093/beheco/arz111},
  abstract = {Market-like situations emerge when trading partners exchange goods and services in nature. Using a marine cleaning mutualism as a study model, we show that mark},
  file = {C\:\\Users\\andre\\Zotero\\storage\\SYXAWWDY\\Triki et al. - 2019 - Biological market effects predict cleaner fish str.pdf;C\:\\Users\\andre\\Zotero\\storage\\PA2JCYAH\\5525119.html},
  journal = {Behav Ecol},
  language = {en},
  number = {6}
}

@article{triki_Decrease_2018,
  title = {A Decrease in the Abundance and Strategic Sophistication of Cleaner Fish after Environmental Perturbations},
  author = {Triki, Zegni and Wismer, Sharon and Levorato, Elena and Bshary, Redouan},
  year = {2018},
  month = jan,
  volume = {24},
  pages = {481--489},
  issn = {1365-2486},
  doi = {10.1111/gcb.13943},
  abstract = {Coral reef ecosystems are declining worldwide and under foreseeable threat due to climate change, resulting in significant changes in reef communities. It is unknown, however, how such community changes impact interspecific interactions. Recent extreme weather events affecting the Great Barrier Reef, that is, consecutive cyclones and the 2016 El Ni\~no event, allowed us to explore potential consequences in the mutualistic interactions involving cleaner fish Labroides dimidiatus (hereafter ``cleaner''). After the perturbations, cleaner densities were reduced by 80\%, disproportionally compared to the variety of reef fish clients from which cleaners remove ectoparasites. Consequently, shifts in supply and demand yielded an increase in the clients' demand for cleaning. Therefore, clients became less selective toward cleaners, whereas cleaners were able to choose from a multitude of partners. In parallel, we found a significant decline in the ability of cleaners to manage their reputation and to learn to prioritize ephemeral food sources to maximize food intake in laboratory experiments. In other words, cleaners failed to display the previously documented strategic sophistication that made this species a prime example for fish intelligence. In conclusion, low population densities may cause various effects on individual behavior, and as a consequence, interspecific interactions. At the same time, our data suggest that a recovery of population densities would cause a recovery of previously described interaction patterns and cleaner strategic sophistication within the lifetime of individuals.},
  copyright = {\textcopyright{} 2017 John Wiley \& Sons Ltd},
  file = {C\:\\Users\\andre\\Zotero\\storage\\HNRM5IP6\\Triki et al. - 2018 - A decrease in the abundance and strategic sophisti.pdf;C\:\\Users\\andre\\Zotero\\storage\\RXVMVK7U\\gcb.html},
  journal = {Global Change Biology},
  keywords = {biological market,coral bleaching,cyclones,El Niño,learning,marine cleaning mutualism},
  language = {en},
  number = {1}
}

@article{trimmer_Does_2012,
  title = {Does Natural Selection Favour the {{Rescorla}}\textendash{{Wagner}} Rule?},
  author = {Trimmer, Pete C. and McNamara, John M. and Houston, Alasdair I. and Marshall, James A. R.},
  year = {2012},
  month = jun,
  volume = {302},
  pages = {39--52},
  issn = {0022-5193},
  doi = {10.1016/j.jtbi.2012.02.014},
  abstract = {A fundamental question relating to animal behaviour is how animals learn; in particular, how they come to associate stimuli with rewards. Numerous empirical findings can be explained by assuming that animals use some mechanism similar to the Rescorla\textendash Wagner learning rule, which is a relatively simple and highly general method of updating the associative strength between different stimuli. However, the Rescorla\textendash Wagner rule is often not optimal, which raises the question of why a rule with such properties should have evolved. We consider the evolution of learning rules in a simple environment where there exists an optimal rule of similar complexity to the Rescorla\textendash Wagner rule. We show that because the Rescorla\textendash Wagner rule is less sensitive to changes in its parameters than the optimal rule, there is a wider range of parameter values over which the rule structure is initially viable. Consequently, the Rescorla\textendash Wagner rule can be favoured by natural selection, ahead of other rules which are more accurate.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\89UHI79H\\Trimmer et al. - 2012 - Does natural selection favour the Rescorla–Wagner .pdf;C\:\\Users\\andre\\Zotero\\storage\\4HU8ZRQI\\S0022519312000872.html},
  journal = {Journal of Theoretical Biology},
  keywords = {Associative value,Classical conditioning,Learning rule,Natural selection,Rescorla–Wagner}
}

@article{trimmer_Mammalian_2008,
  title = {Mammalian Choices: Combining Fast-but-Inaccurate and Slow-but-Accurate Decision-Making Systems},
  shorttitle = {Mammalian Choices},
  author = {Trimmer, Pete C. and Houston, Alasdair I. and Marshall, James A. R. and Bogacz, Rafal and Paul, Elizabeth S. and Mendl, Mike T. and McNamara, John M.},
  year = {2008},
  month = oct,
  volume = {275},
  pages = {2353--2361},
  issn = {0962-8452, 1471-2954},
  doi = {10.1098/rspb.2008.0417},
  abstract = {Empirical findings suggest that the mammalian brain has two decision-making systems that act at different speeds. We represent the faster system using standard signal detection theory. We represent the slower (but more accurate) cortical system as the integration of sensory evidence over time until a certain level of confidence is reached. We then consider how two such systems should be combined optimally for a range of information linkage mechanisms. We conclude with some performance predictions that will hold if our representation is realistic.},
  copyright = {\textcopyright{} 2008 The Royal Society},
  file = {C\:\\Users\\andre\\Zotero\\storage\\CPQ72PXP\\Trimmer et al. - 2008 - Mammalian choices combining fast-but-inaccurate a.pdf;C\:\\Users\\andre\\Zotero\\storage\\3YGIYQUA\\2353.html},
  journal = {Proceedings of the Royal Society of London B: Biological Sciences},
  language = {en},
  number = {1649},
  pmid = {18611852}
}

@article{wareham_Roles_2018,
  title = {The {{Roles}} of {{Internal Representation}} and {{Processing}} in {{Problem Solving Involving Insight}}: {{A Computational Complexity Perspective}}},
  shorttitle = {The {{Roles}} of {{Internal Representation}} and {{Processing}} in {{Problem Solving Involving Insight}}},
  author = {Wareham, Todd},
  year = {2018},
  month = jan,
  volume = {10},
  issn = {1932-6246},
  doi = {10.7771/1932-6246.1201},
  file = {C\:\\Users\\andre\\Zotero\\storage\\M6HU2A4I\\3.html},
  journal = {The Journal of Problem Solving},
  number = {1}
}

@article{wheatcroft_Blueprint_2015,
  title = {A Blueprint for Vocal Learning: Auditory Predispositions from Brains to Genomes},
  shorttitle = {A Blueprint for Vocal Learning},
  author = {Wheatcroft, David and Qvarnstr{\"o}m, Anna},
  year = {2015},
  month = aug,
  volume = {11},
  pages = {20150155},
  issn = {1744-9561, 1744-957X},
  doi = {10.1098/rsbl.2015.0155},
  abstract = {Memorizing and producing complex strings of sound are requirements for spoken human language. We share these behaviours with likely more than 4000 species of songbirds, making birds our primary model for studying the cognitive basis of vocal learning and, more generally, an important model for how memories are encoded in the brain. In songbirds, as in humans, the sounds that a juvenile learns later in life depend on auditory memories formed early in development. Experiments on a wide variety of songbird species suggest that the formation and lability of these auditory memories, in turn, depend on auditory predispositions that stimulate learning when a juvenile hears relevant, species-typical sounds. We review evidence that variation in key features of these auditory predispositions are determined by variation in genes underlying the development of the auditory system. We argue that increased investigation of the neuronal basis of auditory predispositions expressed early in life in combination with modern comparative genomic approaches may provide insights into the evolution of vocal learning.},
  copyright = {\textcopyright{} 2015 The Author(s). Published by the Royal Society. All rights reserved.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\AUACWFRM\\Wheatcroft and Qvarnström - 2015 - A blueprint for vocal learning auditory predispos.pdf;C\:\\Users\\andre\\Zotero\\storage\\XRGSK59N\\20150155.html},
  journal = {Biology Letters},
  language = {en},
  number = {8},
  pmid = {26246333}
}

@article{wismer_Generalized_2016,
  title = {Generalized Rule Application in Bluestreak Cleaner Wrasse ({{Labroides}} Dimidiatus): Using Predator Species as Social Tools to Reduce Punishment},
  shorttitle = {Generalized Rule Application in Bluestreak Cleaner Wrasse ({{Labroides}} Dimidiatus)},
  author = {Wismer, Sharon and Grutter, Alexandra and Bshary, Redouan},
  year = {2016},
  month = jul,
  volume = {19},
  pages = {769--778},
  issn = {1435-9456},
  doi = {10.1007/s10071-016-0975-4},
  abstract = {Generalized rule application promotes flexible behavior by allowing individuals to adjust quickly to environmental changes through generalization of previous learning. Here, we show that bluestreak `cleaner' wrasse (Labroides dimidiatus) uses generalized rule application in their use of predators as social tools against punishing reef fish clients. Punishment occurs as cleaners do not only remove ectoparasites from clients, but prefer to feed on client mucus (constituting cheating). We tested for generalized rule application in a series of experiments, starting by training cleaners to approach one of two fish models in order to evade punishment (by chasing) from a `cheated' client model. Cleaners learned this task only if the safe haven was a predator model. During consecutive exposure to pairs of novel species, including exotic models, cleaners demonstrated generalization of the `predators-are-safe-havens' rule by rapidly satisfying learning criteria. However, cleaners were not able to generalize to a `one-of-two-stimuli-presents-a-safe-haven' rule, as they failed to solve the task when confronted with either two harmless fish models or two predator models. Our results emphasize the importance of ecologically relevant experiments to uncover complex cognitive processes in non-human animals, like generalized rule learning in the context of social tool use in a fish.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\8CCWCQ3X\\Wismer et al. - 2016 - Generalized rule application in bluestreak cleaner.pdf},
  journal = {Anim Cogn},
  keywords = {Cleaner fish,Cognition,Generalization,Labroides dimidiatus,Rule learning,Social tool use},
  language = {en},
  number = {4}
}

@article{woodbury_Learning_1943,
  title = {The Learning of Stimulus Patterns by Dogs.},
  author = {Woodbury, CHARLES B.},
  year = {1943},
  volume = {35},
  pages = {29},
  file = {C\:\\Users\\andre\\Zotero\\storage\\YSEJCVNC\\woodbury1943.pdf},
  journal = {Journal of Comparative Psychology},
  number = {1}
}

@article{zentall_Early_2017,
  title = {Early Commitment Facilitates Optimal Choice by Pigeons},
  author = {Zentall, Thomas R. and Case, Jacob P. and Berry, Jonathan R.},
  year = {2017},
  month = jun,
  volume = {24},
  pages = {957--963},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-016-1173-8},
  abstract = {Prior commitment has been found to facilitate choice of a larger later reward (e.g., healthy living) and avoid the impulsive choice of the smaller immediate reward (e.g., smoking, drug taking). In this research with pigeons, we investigated the ephemeral choice task in which pigeons are given a choice between two alternatives, A and B, with similar reinforcement provided for each; however, if they choose A, they can also choose B, whereas if they choose B, A is removed. Thus, choosing A gives them two rewards, whereas choosing B gives them only one. Paradoxically, pigeons actually show a preference for B, the suboptimal alternative. We tested the hypothesis that pigeons made suboptimal choices because they were impulsive. To reduce impulsivity, we required the pigeons to make their initial choice 20 s before receiving the first reward. We found that requiring the pigeons to make a prior commitment encouraged them to choose optimally. The control group, for which the reward was provided immediately following initial choice, continued to choose suboptimally. The results confirm that requiring animals to make a prior commitment can facilitate the development of optimal choice. Furthermore, they may help explain why, without prior commitment, impulsive species, such as primates and pigeons have difficulty with this task, whereas presumably less impulsive species, such as wrasse fish and under some conditions parrots, are able to choose optimally even without prior commitment.},
  file = {C\:\\Users\\andre\\Zotero\\storage\\3UBNX2BH\\s13423-016-1173-8.html},
  journal = {Psychon Bull Rev},
  language = {en},
  number = {3}
}


